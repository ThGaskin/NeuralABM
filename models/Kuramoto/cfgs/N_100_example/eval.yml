# ======================================================================================================================
#  ╦  ╦╔═╗╦═╗╦╔═╗╔╗ ╦  ╔═╗╔═╗
#  ╚╗╔╝╠═╣╠╦╝║╠═╣╠╩╗║  ║╣ ╚═╗
#   ╚╝ ╩ ╩╩╚═╩╩ ╩╚═╝╩═╝╚═╝╚═╝
# ======================================================================================================================

.variables:
  colors: &colors
    yellow:       &yellow       '#F5DDA9'
    darkblue:     &darkblue     '#2F7194'
    red:          &red          '#ec7070'
    skyblue:      &skyblue      '#97c3d0'
    green:        &green        '#48675A'
    lightbrown:   &lightbrown   '#C6BFA2'
    orange:       &orange       '#EC9F7E'
    lightgreen:   &lightgreen   '#AFD8BC'
    grey:         &grey         '#3D4244'

  # Page widths in inches for latex documents: ensures easy integration into latex documents
  page_widths:
    full_width:         &full_width         7.5
    half_width:         &half_width         !expr 7.5 / 2
    two_thirds_width:   &two_thirds_width   !expr 2 * 7.5 / 3
    third_width:        &third_width        !expr 7.5 / 3
    quarter_width:      &quarter_width      !expr 7.5 / 4
    fifth_width:        &fifth_width        !expr 7.5 / 5
    eighth_width:       &eighth_width       !expr 7.5 / 8

.matrix_defaults:
  style:
    figure.figsize: [ *third_width, *third_width ]
    axes.grid: False
    axes.spines.top: True
    axes.spines.right: True
    axes.linewidth: 0.5
  vmax: 1
  helpers:
    set_title:
      title: ''
    set_ticks:
      x:
        major: []
      y:
        major: []
    set_labels:
      x: ' '
      y: ' '
    set_limits:
      y: [max, min]
      x: [min, max]

# ======================================================================================================================
# ╔═╗╦  ╔═╗╔╦╗╔═╗
# ╠═╝║  ║ ║ ║ ╚═╗
# ╩  ╩═╝╚═╝ ╩ ╚═╝
# ======================================================================================================================

# Plot the training and Frobenius loss
losses:
  based_on: loss
  figsize: [*half_width, *third_width]

# Plot the true adjacency matrix
true_network:
  based_on:
    - adjacency_matrix
    - .matrix_defaults
  cbar_kwargs:
    label: True edge weight $a_{ij}$

# Plot the predicted adjacency matrix
predicted_network:
  based_on: true_network
  select:
    data:
      path: output_data/predictions
      transform:
        - .isel: [!dag_prev , {time: -1}]
  cbar_kwargs:
    label: Predicted edge weight $\hat{a}_{ij}$

# Plot the prediction error on the matrices
error:
  based_on:
    - accuracy
    - .matrix_defaults
  norm:
    name: LogNorm
  vmin: 1e-7
  vmax: ~
  cbar_kwargs:
    label: Prediction error $\vert \hat{a}_{ij} - a_{ij} \vert$
  cmap:
    from_values:
      0: white
      0.5: *yellow
      1: *red

# Plot the degree distribution with uncertainty
degree:
  based_on: .multiplot_universe
  dag_options:
    meta_operations:
      hist:
        - np.linspace: [ 0, 10, 500 ]
        - NeuralABM.hist: [ !arg 0 ]
          kwargs: { bins: !dag_node -1, axis: 1 }
  select:
    param_binned:
      path: output_data/predictions
      transform:
        - .sum: [!dag_prev , i ]
        - hist: [!dag_prev ]
    true_val:
      path: true_network/_degree_weighted
      transform:
        - hist: [ !dag_prev ]
    loss:
      path: output_data/Training loss
      transform:
        - mul: [!dag_prev , -1]
        - np.exp: [!dag_prev ]

  transform:

    # Get the true value
    - NeuralABM.flatten_dims: [ !dag_tag true_val , { sample: [ time ] } ]
    - NeuralABM.normalise_degrees_to_edges: [ !dag_prev ]
    - .squeeze: [ !dag_prev ]
    - .to_dataset: [!dag_prev ]
      kwargs: {name: y}
      tag: true_param

    # Calculate mean, MLE, and error
    - NeuralABM.flatten_dims: [ !dag_tag param_binned , { sample: [ time ] } ]
    - NeuralABM.normalise_degrees_to_edges: [!dag_prev ]
      tag: samples
    - NeuralABM.flatten_dims: [ !dag_tag loss , { sample: [ time ] } ]
    - .expand_dims: [!dag_prev ]
      kwargs:
        bin_center: 1
        axis: -1
      tag: loss_flattened
    - .sum: [!dag_prev , 'sample']
    - div: [!dag_tag loss_flattened, !dag_prev ]
      tag: loss_normalised
    - .coords: [!dag_tag loss , 'time']
    - len: [!dag_prev ]
      tag: n_steps
    - .isel: [!dag_tag loss , {time: -1}]
      kwargs: {drop: true}
    - .argmax: [!dag_prev ]
    - mul: [!dag_prev , !dag_tag n_steps]
    - sub: [!dag_prev , 1]
    - NeuralABM.marginal_of_density: [ !dag_tag samples ]
      kwargs:
        loss: !dag_tag loss_normalised
        error: Hellinger
        MLE_index: !dag_prev
      tag: data
  to_plot:
    - function: [model_plots.HarrisWilson, plot_prob_density]
      args: [!dag_result data]
      x: bin_center
      y: MLE
      yerr: yerr
      pass_helper: true
      color: *darkblue
    - function: [model_plots.HarrisWilson, plot_prob_density]
      args: [ !dag_result true_param ]
      y: y
      linestyle: dotted
      color: *red
      pass_helper: True
  x: bin_center
  smooth_kwargs:
    enabled: True
    sigma: 3
  helpers:
    set_title:
      title: ~
    set_labels:
      x: Weighted degree $k$
      y: $P(k)$
    set_legend:
      use_legend: True
      ncol: 1
      loc: upper right
    set_limits:
      x: [0, 10]
      y: [0, ~]
  style:
    figure.figsize: [*half_width, *quarter_width]

# Plot the triangle distribution with uncertainty
triangles:
  based_on: degree
  dag_options:
    meta_operations:
      hist:
        - np.linspace: [ 0, 5, 500 ]
        - NeuralABM.hist: [ !arg 0 ]
          kwargs: { bins: !dag_node -1, axis: 1 }
  select:
    param_binned:
      path: output_data/predictions
      transform:
        - .data: [ !dag_prev ]
        - NeuralABM.triangles: [ !dag_prev ]
        - hist: [!dag_prev ]
    true_val:
      path: true_network/_triangles_weighted
  helpers:
    set_limits:
      x: [0, 5]
    set_labels:
      x: Weighted triangle count $t$
      y: $P(t)$

# ======================================================================================================================
#  ╦  ╦╔═╗╦═╗╦╔═╗╔╗ ╦  ╔═╗╔═╗
#  ╚╗╔╝╠═╣╠╦╝║╠═╣╠╩╗║  ║╣ ╚═╗
#   ╚╝ ╩ ╩╩╚═╩╩ ╩╚═╝╩═╝╚═╝╚═╝
# ======================================================================================================================

.variables:
  colors: &colors
    yellow:       &yellow       '#F5DDA9'
    darkblue:     &darkblue     '#2F7194'
    red:          &red          '#ec7070'
    skyblue:      &skyblue      '#97c3d0'
    green:        &green        '#48675A'
    lightbrown:   &lightbrown   '#C6BFA2'
    orange:       &orange       '#EC9F7E'
    lightgreen:   &lightgreen   '#AFD8BC'
    grey:         &grey         '#3D4244'

  # Page widths in inches for latex documents: ensures easy integration into latex documents
  page_widths:
    full_width:     &full_width         7.5
    half_width:     &half_width         !expr 7.5 / 2
    third_width:    &third_width        !expr 7.5 / 3
    quarter_width:  &quarter_width      !expr 7.5 / 4
    fifth_width:    &fifth_width        !expr 7.5 / 5
    eighth_width:    &eighth_width      !expr 7.5 / 8

# ======================================================================================================================
# ╔═╗╦  ╔═╗╔╦╗╔═╗
# ╠═╝║  ║ ║ ║ ╚═╗
# ╩  ╩═╝╚═╝ ╩ ╚═╝
# ======================================================================================================================
# Compare the losses as a function of the noise
loss_compared:
  based_on: .line_multiverse
  select_and_combine:
    fields:
      loss:
        path: output_data/Loss
        transform:
          - .isel: [!dag_prev , {time: -1}]
  transform:
    - .mean: [!dag_tag loss, 'seed']
      tag: data
  x: sigma
  hue: kind
  style:
    figure.figsize: [ *half_width, *quarter_width ]
  helpers:
    set_scales:
      x: log
      y: log
    set_labels:
      x: Noise level $\sigma$
      y: Final loss
    set_legend:
      ncol: 5

# Plot the degree distribution for low and high noise levels
degree_distribution: !pspace
  dag_options:
    define:
      lower_bin: 0
      upper_bin: 100
      n_bins: 400
  based_on: .multiplot_multiverse
  select_and_combine:
    subspace:
      sigma: !sweep
        default: 0
        values: [0, 1e-4, 1e-3, 1e-2, 1e-1]
    fields:
      true_densities_stacked:
        subspace:
          sigma: 0
          seed: 0
        path: true_network/_degree_weighted
        transform:
          - np.linspace: [ !dag_tag lower_bin, !dag_tag upper_bin, !dag_tag n_bins]
          - hist: [ !dag_node -2 ]
            kwargs:
              bins: !dag_node -1

      predicted_densities_stacked:
        path: output_data/predictions
        transform:
          - .sum: [ !dag_prev , i ]
          - np.linspace: [ !dag_tag lower_bin, !dag_tag upper_bin, !dag_tag n_bins]
          - hist: [ !dag_node -2 ]
            kwargs:
              bins: !dag_node -1
              along_dim: [j]

      loss:
        path: output_data/Loss
        transform:
          - .sel: [ !dag_prev , { kind: Data loss } ]
          - mul: [!dag_prev , -1]
          - np.exp: [!dag_prev ]

  transform:

    # Flatten the true densities dataset
    - normalise_to_nw_size: [ !dag_tag true_densities_stacked  ]
      kwargs: {x: 'bin_center'}
    - .squeeze: [ !dag_prev ]
      tag: true_densities

    # Flatten the predicted densities
    - flatten_dims: [ !dag_tag predicted_densities_stacked , [ seed, sigma, time ] , sample ]
    - normalise_to_nw_size: [ !dag_prev  ]
      kwargs: {x: 'bin_center'}
      tag: predicted_densities

    # Flatten and normalise the probabilities
    - flatten_dims: [ !dag_tag loss , [ seed, sigma, time ], sample ]
    - .sum: [ !dag_prev ]
    - div: [ !dag_node -2, !dag_prev ]
      tag: probabilities

    # Calculate the marginal density
    - marginal_of_density: [ !dag_tag predicted_densities, !dag_tag probabilities ]
      kwargs:
        error: Hellinger
        sample_dim: 'sample'
      tag: marginals

    # Get the MLE
    - .argmax: [!dag_tag probabilities]
    - .isel: [!dag_tag predicted_densities, {sample: !dag_prev }]
      kwargs: {drop: true}
    - .rename: [!dag_prev , {predictions: 'MLE'}]
      tag: MLE

    # Merge
    - xr.merge: [[!dag_tag marginals, !dag_tag MLE]]
      tag: data

  to_plot:
    - function: [model_plots.HarrisWilson, plot_prob_density]
      args: [!dag_result data]
      y: MLE
      yerr: err
      pass_helper: true
      color: *darkblue
      label: $\hat{P}(k)$
    - function: [model_plots.HarrisWilson, plot_prob_density]
      args: [ !dag_result true_densities ]
      y: _degree_weighted
      linestyle: dotted
      color: *red
      pass_helper: True
      label: $P(k)$
  x: bin_center
  smooth_kwargs:
    enabled: True
    sigma: 1.5
  helpers:
    set_legend:
      use_legend: False
    set_limits:
      x: [0, 30]
      y: [0, 0.25]
    set_title:
      title: ~
    set_labels:
      x: Weighted degree $k$
      y: $P(k)$
  style:
    figure.figsize: [*half_width, *quarter_width]

# Distribution of triangles for the low and high noise levels
triangle_distribution: !pspace
  based_on: degree_distribution
  dag_options:
    define:
      upper_bin: 1000
      n_bins: 1000
  select_and_combine:
    fields:
      true_densities_stacked:
        path: true_network/_triangles_weighted

      predicted_densities_stacked:
        path: output_data/predictions
        transform:
          - .data: [!dag_prev ]
          - triangles: [ !dag_prev ]
          - np.linspace: [ !dag_tag lower_bin, !dag_tag upper_bin, !dag_tag n_bins]
          - hist: [ !dag_node -2 ]
            kwargs:
              bins: !dag_prev
              along_dim: [i]
  to_plot:
    - function: [ model_plots.HarrisWilson, plot_prob_density ]
      args: [ !dag_result data ]
      y: MLE
      yerr: err
      pass_helper: true
      color: *darkblue
      label: $\hat{P}(t)$
    - function: [ model_plots.HarrisWilson, plot_prob_density ]
      args: [ !dag_result true_densities ]
      y: _triangles_weighted
      linestyle: dotted
      color: *red
      pass_helper: True
      label: $P(t)$
  helpers:
    set_labels:
      x: Weighted triangles $t$
      y: $P(t)$
    set_limits:
      x: [0.5, 40]
      y: [0, 0.15]

# The different error metrics for the degree distribution
degree_error:
  based_on: .line_multiverse
  select_and_combine:
    fields:
      predictions:
        path: output_data/predictions
        transform:
          - .sum: [!dag_prev , i]
          - np.linspace: [ !dag_tag lower_bin, !dag_tag upper_bin, !dag_tag n_bins]
          - hist: [ !dag_node -2 ]
            kwargs:
              bins: !dag_node -1
              along_dim: [j]
      loss:
        path: output_data/Loss
        transform:
          - .sel: [!dag_prev , {kind: Data loss}]
          - mul: [!dag_prev , -1]
          - np.exp: [!dag_prev ]
  dag_options:
    define:
      lower_bin: 0
      upper_bin: 100
      n_bins: 400
    meta_operations:

      stack_and_normalise_loss:
        # Stack the seed and time dimensions and normalise over this stacked dimension
        - flatten_dims: [!arg 0 , [seed, time], sample]
        - .sum: [ !dag_prev , 'sample' ]
        - div: [ !dag_node -2, !dag_prev ]

      stack_and_normalise_predictions:
        # Stack the seed and time dimensions of the predictions and normalise to the network size
        - flatten_dims: [!arg 0 , [seed, time], sample]
        - normalise_to_nw_size: [!dag_prev ]
          kwargs:
            exclude_dim: ['sigma']
            x: 'bin_center'

      average_hellinger_distance:
        # Calculate the average Hellinger distance between the samples and the MLE
        - Hellinger_distance: [ !arg 0, !arg 1 ]
          kwargs: {sum: True, x: 'bin_center'}
        - mul: [ !dag_prev , !arg 2 ]
        - .sum: [ !dag_prev , 'sample' ]
        - .rename: [ !dag_prev , {predictions: 'err'} ]

      average_relative_entropy:
        # Calculate the average relative entropy between the samples and the MLE
        - relative_entropy: [ !arg 0, !arg 1 ]
          kwargs: {sum: True, x: 'bin_center'}
        - mul: [ !dag_prev , !arg 2 ]
        - .sum: [ !dag_prev , 'sample' ]
        - .rename: [ !dag_prev , {predictions: 'err'} ]

  transform:
    - stack_and_normalise_loss: [ !dag_tag loss ]
      tag: probabilities

    - stack_and_normalise_predictions: [!dag_tag predictions]
      tag: samples

    # Get the maximum likelihood estimator for each noise level and seed
    - .argmax: [!dag_tag probabilities, 'sample']
    - .isel: [!dag_tag samples, {sample: !dag_prev }]
    - .drop_vars: [!dag_prev , 'sample']
      tag: MLE

    # Calculate the average errors (in both metrics) and combine
    - average_hellinger_distance: [!dag_tag samples, !dag_tag MLE, !dag_tag probabilities]
      tag: hellinger
    - average_relative_entropy: [ !dag_tag samples, !dag_tag MLE, !dag_tag probabilities ]
    - concat_along: [[!dag_tag hellinger, !dag_prev ], 'metric', [ 'Hellinger metric', 'Relative entropy'] ]
    - .to_array: [!dag_prev ]
      file_cache:
        read: False
        write: True
      tag: data

  x: sigma
  hue: metric

  helpers:
    set_legend:
      use_legend: true
    set_labels:
      x: $\sigma$
      y: ' '
    set_title:
      title: ' '
    set_scales:
      x: log
    set_tick_locators:
      x:
        major: {base: 10, name: LogLocator, numticks: 12}
        minor:
          base: 10
          name: LogLocator
          numticks: 12
          subs: [0.2, 0.4, 0.6, 0.8]
  style:
    figure.figsize: [*third_width, *third_width]


# The different error metrics for the triangle distribution
triangle_error:
  based_on: degree_error
  dag_options:
    define:
      upper_bin: 1000
      n_bins: 1000
  select_and_combine:
    fields:
      param:
        path: output_data/predictions
        transform:
          - .data: [!dag_prev ]
          - triangles: [ !dag_prev ]
          - np.linspace: [ !dag_tag lower_bin, !dag_tag upper_bin, !dag_tag n_bins]
          - hist: [ !dag_node -2 ]
            kwargs:
              bins: !dag_prev
              along_dim: [i]
  helpers:
    set_legend:
      use_legend: False

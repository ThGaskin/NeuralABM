diff --git a/models/Kuramoto/Kuramoto_base_plots.yml b/models/Kuramoto/Kuramoto_base_plots.yml
index a03f52a..78ca510 100644
--- a/models/Kuramoto/Kuramoto_base_plots.yml
+++ b/models/Kuramoto/Kuramoto_base_plots.yml
@@ -24,6 +24,7 @@
 .default_style:
   style:
     text.usetex:        True
+    text.latex.preamble: \usepackage{amssymb} \usepackage{amsmath}
     mathtext.fontset:   cm
     font.family:        serif
     font.size:          &font_size 10
diff --git a/models/Kuramoto/README.md b/models/Kuramoto/README.md
index 7e40f8a..858861b 100644
--- a/models/Kuramoto/README.md
+++ b/models/Kuramoto/README.md
@@ -133,6 +133,8 @@ The following configuration sets are included in the model:

 - `Computational_performance`: trains the model for 10 epochs for different network sizes, and plots the average
 compute times.
+- `Convexity`: plot the error on the predicted degree distribution as a function of the rank of the Gram matrix of
+observations
 - `N_100_example`: infers two networks with 100 nodes for noiseless and noisy training data, and plots the results,
 including the inferred degree and triangle distributions
 - `N_1000_example`: same as for `N_100_example`, but for 1000 nodes.
diff --git a/models/Kuramoto/__init__.py b/models/Kuramoto/__init__.py
index c16b4a1..75c29be 100644
--- a/models/Kuramoto/__init__.py
+++ b/models/Kuramoto/__init__.py
@@ -1,3 +1,3 @@
 from .ABM import Kuramoto_ABM
 from .DataGeneration import get_data
-from .regression import regression
+from .regression import rank, regression
diff --git a/models/Kuramoto/cfgs/Convexity/eval.yml b/models/Kuramoto/cfgs/Convexity/eval.yml
index e69de29..9fbfc79 100644
--- a/models/Kuramoto/cfgs/Convexity/eval.yml
+++ b/models/Kuramoto/cfgs/Convexity/eval.yml
@@ -0,0 +1,296 @@
+# ======================================================================================================================
+#  ╦  ╦╔═╗╦═╗╦╔═╗╔╗ ╦  ╔═╗╔═╗
+#  ╚╗╔╝╠═╣╠╦╝║╠═╣╠╩╗║  ║╣ ╚═╗
+#   ╚╝ ╩ ╩╩╚═╩╩ ╩╚═╝╩═╝╚═╝╚═╝
+# ======================================================================================================================
+
+.variables:
+  colors: &colors
+    yellow:         &yellow           '#F5DDA9'
+    darkblue:       &darkblue         '#2F7194'
+    red:            &red              '#ec7070'
+    skyblue:        &skyblue          '#97c3d0'
+    darkgreen:      &darkgreen        '#48675A'
+    lightbrown:     &lightbrown       '#C6BFA2'
+    orange:         &orange           '#EC9F7E'
+    lightgreen:     &lightgreen       '#AFD8BC'
+    grey:           &grey             '#3D4244'
+    pink:           &pink             '#F8A6A6'
+
+
+  # Page widths in inches for latex documents: ensures easy integration into latex documents
+  page_widths:
+    full_width:         &full_width         7.5
+    half_width:         &half_width         !expr 7.5 / 2
+    two_thirds_width:   &two_thirds_width   !expr 2 * 7.5 / 3
+    third_width:        &third_width        !expr 7.5 / 3
+    quarter_width:      &quarter_width      !expr 7.5 / 4
+    fifth_width:        &fifth_width        !expr 7.5 / 5
+    eighth_width:       &eighth_width       !expr 7.5 / 8
+
+# ======================================================================================================================
+# ╔═╗╦  ╔═╗╔╦╗╔═╗
+# ╠═╝║  ║ ║ ║ ╚═╗
+# ╩  ╩═╝╚═╝ ╩ ╚═╝
+# ======================================================================================================================
+
+# Plot the losses
+loss:
+  based_on: loss
+  figsize: [*half_width, *third_width]
+
+convexity:
+  based_on: .line_multiverse
+  select_and_combine:
+    fields:
+      rank: regression_data/rank
+  transform:
+    - .mean: [!dag_tag rank, 'vertex_idx']
+      tag: mean
+    - .min: [!dag_tag rank, 'vertex_idx']
+      tag: min
+    - .max: [!dag_tag rank, 'vertex_idx']
+      tag: max
+    - concat_along: [[!dag_tag mean, !dag_tag min, !dag_tag max], 'kind', ['mean', 'min', 'max']]
+      tag: data
+  hue: kind
+  x: training_set_size
+
+# True adjacency matrix
+Adjacency_matrices/true_adjacency_matrix:
+  based_on: adjacency_matrix
+
+# Predicted adjacency matrix
+Adjacency_matrices/prediction:
+  based_on: adjacency_matrix
+  select:
+    data:
+      path: output_data/predictions
+      transform:
+        - .isel: [!dag_prev , {time: -1}]
+
+# L1 error on each edge
+Adjacency_matrices/error:
+  based_on: error
+
+# Plot the degree distribution with uncertainty
+degree_marginal:
+  based_on: degree_marginal
+  dag_options:
+    define:
+      upper_bin: 20
+  helpers:
+    set_limits:
+      x: [ 0, 20 ]
+      y: [ 0, ~ ]
+  style:
+    figure.figsize: [ *half_width, *quarter_width ]
+
+# Error over convexity
+convexity_error:
+  based_on: .line_multiverse
+  dag_options:
+    define:
+      lower_bin: 0
+      upper_bin: 20
+      n_bins: 500
+  select_and_combine:
+    fields:
+      N:
+        path: ../cfg
+        transform:
+          - recursive_getitem: [!dag_prev , ['Kuramoto', 'Data', 'synthetic_data', 'N']]
+        subspace:
+          seed: 0
+          training_set_size: 2
+      rank: regression_data/rank
+      predicted_densities:
+        path: output_data/predictions
+        transform:
+          - .sum: [ !dag_prev , i ]
+          - np.linspace: [ !dag_tag lower_bin, !dag_tag upper_bin, !dag_tag n_bins ]
+          - hist_ndim: !dag_node -2
+            kwargs:
+              bins: !dag_prev
+              exclude_dim: [ 'time' ]
+
+      loss:
+        path: output_data/Loss
+        transform:
+          - .sel: [ !dag_prev , { kind: Data loss } ]
+          - mul: [!dag_prev , -1]
+          - np.exp: [!dag_prev ]
+  transform:
+    - .min: [ !dag_tag rank, 'vertex_idx' ]
+    - .mean: [!dag_prev , 'seed']
+    - .data: [!dag_prev ]
+    - div: [!dag_prev , 19 ]
+      tag: min_rank
+
+    # Flatten the predicted densities
+    - flatten_dims: [ !dag_tag predicted_densities , [ seed, time ] , sample ]
+    - normalise_to_nw_size: [ !dag_prev  ]
+      kwargs: {x: 'bin_center'}
+      tag: degrees
+
+    # Flatten and normalise the probabilities
+    - flatten_dims: [ !dag_tag loss , [ seed, time ], sample ]
+    - .sum: [ !dag_prev ]
+    - div: [ !dag_node -2, !dag_prev ]
+      tag: probabilities
+
+    # Get total Hellinger error
+    - marginal_of_density: [ !dag_tag degrees, !dag_tag probabilities ]
+      kwargs:
+        error: Hellinger
+        sample_dim: 'sample'
+        exclude_dim: ['training_set_size']
+      file_cache:
+        write: True
+        read: True
+    - getitem: [!dag_prev , 'err']
+    - .sum: [!dag_prev , 'bin_center']
+    - .rename: [!dag_prev , {'training_set_size': 'min_rank'}]
+    - .assign_coords: [!dag_prev , {min_rank: !dag_tag min_rank}]
+      tag: data_Hellinger
+
+    # Get total relative entropy error
+    - marginal_of_density: [ !dag_tag degrees, !dag_tag probabilities ]
+      kwargs:
+        error: relative_entropy
+        sample_dim: 'sample'
+        exclude_dim: [ 'training_set_size' ]
+      file_cache:
+        write: True
+        read: True
+    - getitem: [ !dag_prev , 'err' ]
+    - .sum: [ !dag_prev , 'bin_center' ]
+    - .rename: [ !dag_prev , { 'training_set_size': 'min_rank' } ]
+    - .assign_coords: [ !dag_prev , { min_rank: !dag_tag min_rank } ]
+    - concat_along: [[!dag_tag data_Hellinger, !dag_prev ], 'kind', ['Hellinger error', 'Relative entropy']]
+    - .sel: [!dag_prev , {kind: 'Hellinger error'}]
+      tag: data
+  x: min_rank
+#  hue: kind
+  style:
+    figure.figsize: [*third_width, *third_width]
+  helpers:
+    set_labels:
+      x: $\mathfrak{c} = \min_i \mathbf{G}_i \mathbf{G}_i^T / (N-1)$
+      y: Hellinger error $d_\mathrm{H}$
+    set_title:
+      title: ''
+
+# Error over convexity
+marginal_mv: !pspace
+  based_on: .multiplot_multiverse
+  dag_options:
+    define:
+      lower_bin: 0
+      upper_bin: 20
+      n_bins: 500
+  select_and_combine:
+    subspace:
+      training_set_size: !sweep
+        default: 2
+        values: [2, 16]
+    fields:
+      true_densities:
+        path: true_network/_degree_weighted
+        transform:
+          - np.linspace: [ !dag_tag lower_bin, !dag_tag upper_bin, !dag_tag n_bins ]
+          - hist: !dag_node -2
+            kwargs:
+              bins: !dag_prev
+          - normalise_to_nw_size: [ !dag_prev ]
+            kwargs: { x: bin_center }
+          - .rename: [ !dag_prev , { _degree_weighted: _variable } ]
+        subspace:
+          seed: 0
+          training_set_size: 2
+      predicted_densities:
+        path: output_data/predictions
+        transform:
+          - .sum: [ !dag_prev , i ]
+          - np.linspace: [ !dag_tag lower_bin, !dag_tag upper_bin, !dag_tag n_bins ]
+          - hist_ndim: !dag_node -2
+            kwargs:
+              bins: !dag_prev
+              exclude_dim: [ 'time' ]
+      loss:
+        path: output_data/Loss
+        transform:
+          - .sel: [ !dag_prev , { kind: Data loss } ]
+          - mul: [!dag_prev , -1]
+          - np.exp: [!dag_prev ]
+  transform:
+
+    - .squeeze: [!dag_tag true_densities ]
+      tag: true_vals
+
+    # Flatten the predicted densities
+    - flatten_dims: [ !dag_tag predicted_densities , [ seed, time, training_set_size ] , sample ]
+    - normalise_to_nw_size: [ !dag_prev  ]
+      kwargs: {x: 'bin_center'}
+      tag: degrees
+
+    # Flatten and normalise the probabilities
+    - flatten_dims: [ !dag_tag loss , [ seed, time, training_set_size ], sample ]
+    - .sum: [ !dag_prev ]
+    - div: [ !dag_node -2, !dag_prev ]
+      tag: probabilities
+
+    # Get total Hellinger error
+    - marginal_of_density: [ !dag_tag degrees, !dag_tag probabilities ]
+      kwargs:
+        error: Hellinger
+        sample_dim: 'sample'
+      file_cache:
+        write: False
+        read: True
+      tag: marginals
+
+    # Get the MLE
+    - .argmax: [!dag_tag probabilities]
+    - .isel: [!dag_tag degrees, {sample: !dag_prev }]
+      kwargs: {drop: true}
+    - .rename: [!dag_prev , {predictions: 'MLE'}]
+      tag: MLE
+
+    # Merge
+    - xr.merge: [[!dag_tag marginals, !dag_tag MLE]]
+    - print: [!dag_prev ]
+      tag: data
+  to_plot:
+    - function: [model_plots.HarrisWilson, plot_prob_density]
+      args: [!dag_result data]
+      y: MLE
+      yerr: err
+      pass_helper: true
+      color: *darkblue
+      label: $\hat{P}(k)$
+    - function: [model_plots.HarrisWilson, plot_prob_density]
+      args: [ !dag_result true_vals ]
+      y: _variable
+      linestyle: dotted
+      color: *red
+      pass_helper: True
+      label: $P(k)$
+  x: bin_center
+  smooth_kwargs:
+    enabled: true
+    sigma: 2
+  style:
+    figure.figsize: [*third_width, *third_width]
+  helpers:
+    set_labels:
+      x: $k$
+      y: $P(k)$
+    set_title:
+      title: ''
+    set_limits:
+      x: !coupled-sweep
+        default: [0, 20]
+        target_name: training_set_size
+        values: [[0, 12], [0, 8]]
+
diff --git a/models/Kuramoto/cfgs/Convexity/run.yml b/models/Kuramoto/cfgs/Convexity/run.yml
index e69de29..18caac2 100644
--- a/models/Kuramoto/cfgs/Convexity/run.yml
+++ b/models/Kuramoto/cfgs/Convexity/run.yml
@@ -0,0 +1,37 @@
+---
+paths:
+  model_note: Convexity
+perform_sweep: True
+parameter_space:
+  seed: !sweep
+    default: 0
+    range: [5]
+  num_epochs: !coupled-sweep
+    default: 10
+    values: [4000, 2000, 1000, 500]
+    target_name: training_set_size
+  write_start: 1
+  write_every: 40
+  write_predictions_every: 40
+  calculate_data_rank: true
+  Kuramoto:
+    Data:
+      write_adjacency_matrix: true
+      load_from_dir:
+        network:
+      synthetic_data:
+        num_steps: 3
+        training_set_size: !sweep
+          default: 2
+          values: [2, 4, 8, 16]
+        N: 20
+        sigma: 0
+        network:
+          type: random
+          mean_degree: 6
+          graph_props:
+            is_directed: False
+      dt: 0.02
+      alpha: 0
+    Training:
+      batch_size: 1
diff --git a/models/Kuramoto/regression.py b/models/Kuramoto/regression.py
index 9461d8c..34313b9 100644
--- a/models/Kuramoto/regression.py
+++ b/models/Kuramoto/regression.py
@@ -8,14 +8,14 @@ import torch


 def regression(
-    training_data: torch.Tensor,
-    eigenfrequencies: torch.Tensor,
-    h5file: h5.File,
-    dt: float,
-    *,
-    alpha: float,
-    beta: float,
-    kappa: float
+        training_data: torch.Tensor,
+        eigenfrequencies: torch.Tensor,
+        h5file: h5.File,
+        dt: float,
+        *,
+        alpha: float,
+        beta: float,
+        kappa: float
 ):
     """Estimates the network from first- or second-order dynamics via an OLS-regression, and stores the predictions in
     an h5.File.
@@ -84,7 +84,7 @@ def regression(
     G = torch.reshape(torch.permute(G, (2, 3, 0, 1)), (N, N, -1))

     # Create an h5 Group for the regression output
-    regression_group = h5file.create_group("regression_data")
+    regression_group = h5file.require_group("regression_data")

     # The predicted matrix, estimated column-wise
     A = torch.zeros(N, N)
@@ -97,15 +97,15 @@ def regression(

     # Estimate the coupling vector for each node
     for n in range(N):
-        g = torch.cat((G[n][:n, :], G[n][n + 1 :, :]))
+        g = torch.cat((G[n][:n, :], G[n][n + 1:, :]))
         g_t = torch.transpose(g, 0, 1)
         t = torch.matmul(G[n], G_transpose[n])
-        subsel = torch.cat((t[:n, :], t[n + 1 :, :]), dim=0)
-        subsel = torch.cat((subsel[:, :n], subsel[:, n + 1 :]), dim=1)
+        subsel = torch.cat((t[:n, :], t[n + 1:, :]), dim=0)
+        subsel = torch.cat((subsel[:, :n], subsel[:, n + 1:]), dim=1)

         row_entry = np.matmul(torch.matmul(X[n], g_t), np.linalg.inv(subsel))
         A[n, :] = (
-            1 / kappa * torch.cat((row_entry[:n], torch.tensor([0]), row_entry[n:]))
+                1 / kappa * torch.cat((row_entry[:n], torch.tensor([0]), row_entry[n:]))
         )

     # Write out the time it took to run OLS
@@ -133,3 +133,76 @@ def regression(
     )
     dset_time.attrs["dim_names"] = ["training_time"]
     dset_time[-1] = prediction_time
+
+
+def rank(
+        training_data: torch.Tensor,
+        h5file: h5.File,
+        *,
+        alpha: float
+):
+    """Estimates the network from first- or second-order dynamics via an OLS-regression, and stores the predictions in
+    an h5.File.
+    :param training_data: the training data from which to estimate the network
+    :param h5file: the h5 file to write the predictions to
+    :param alpha: the coefficient of the second derivative
+    """
+
+    # Extract the number of nodes from the training data
+    N = training_data.shape[2]
+
+    if alpha == 0:
+
+        # Stack the sine-couplings into a matrix for each node
+        G = torch.zeros(
+            training_data.shape[0],
+            training_data.shape[1] - 1,
+            training_data.shape[2],
+            N,
+        )
+
+    else:
+
+        G = torch.zeros(
+            training_data.shape[0],
+            training_data.shape[1] - 2,
+            training_data.shape[2],
+            N,
+        )
+
+    t_0 = 1 if alpha != 0 else 0
+    for dset in range(G.shape[0]):
+        for step in range(0, G.shape[1]):
+            G[dset, step] = torch.sin(
+                -training_data[dset, step + t_0] + torch.flatten(training_data[dset, step + t_0])
+            )
+
+    # Permute node and time series indices
+    G = torch.reshape(torch.permute(G, (2, 3, 0, 1)), (N, N, -1))
+
+    # Create an h5 Group for the regression output
+    regression_group = h5file.require_group("regression_data")
+
+    # Transpose G
+    G_transpose = torch.transpose(G, 1, 2)
+
+    ranks = np.zeros(N)
+
+    # Estimate the coupling vector for each node
+    for n in range(N):
+        t = torch.matmul(G[n], G_transpose[n])
+        subsel = torch.cat((t[:n, :], t[n + 1:, :]), dim=0)
+        subsel = torch.cat((subsel[:, :n], subsel[:, n + 1:]), dim=1)
+        ranks[n] = np.linalg.matrix_rank(subsel)
+
+    # Create data group and datasets for the predictions
+    dset_rank = regression_group.create_dataset(
+        "rank",
+        (N,),
+        maxshape=(N,),
+        chunks=True,
+        compression=3,
+    )
+    dset_rank.attrs["dim_names"] = ["vertex_idx"]
+    dset_rank.attrs["coords_mode__vertex_idx"] = "trivial"
+    dset_rank[:, ] = ranks
diff --git a/models/Kuramoto/run.py b/models/Kuramoto/run.py
index 37a2e88..d9f1ed2 100755
--- a/models/Kuramoto/run.py
+++ b/models/Kuramoto/run.py
@@ -502,6 +502,15 @@ if __name__ == "__main__":
             kappa=model_cfg["Data"]["kappa"],
         )

+    # If specified, calculate the ranks of the Gram matrices for each node
+    if cfg.get("calculate_data_rank", False):
+        log.info("   Calculating rank of training data ...")
+        Kuramoto.rank(
+            training_data,
+            h5file,
+            alpha=ABM.alpha
+        )
+
     log.info("   Wrapping up ...")

     h5file.close()

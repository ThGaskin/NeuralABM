diff --git a/include/neural_net.py b/include/neural_net.py
index 7e2859c..cfc3f71 100644
--- a/include/neural_net.py
+++ b/include/neural_net.py
@@ -1,13 +1,13 @@
 import torch
 from torch import nn
-from typing import Any, List
+from typing import Any, List, Union
 
 # -----------------------------------------------------------------------------
 # -- NN utility functions -----------------------------------------------------
 # -----------------------------------------------------------------------------
 
 
-def get_activation_funcs(n_layers: int, cfg: dict = None) -> List[Any]:
+def get_activation_funcs(n_layers: int, cfg: Union[str, dict] = None) -> List[Any]:
 
     """Extracts the activation functions from the config"""
 
@@ -33,16 +33,20 @@ def get_activation_funcs(n_layers: int, cfg: dict = None) -> List[Any]:
 
     if cfg is None:
         return funcs
+    elif isinstance(cfg, str):
+        return [return_function(cfg)] * (n_layers + 1)
+    elif isinstance(cfg, dict):
+        for val in cfg.keys():
+            if val in [0]:
+                funcs[0] = return_function(cfg[0])
+            elif val in [-1]:
+                funcs[-1] = return_function(cfg[-1])
+            else:
+                funcs[val-1] = return_function(cfg[val])
 
-    for val in cfg.keys():
-        if val in ['first', 0]:
-            funcs[0] = return_function(cfg['first'])
-        elif val in ['last', -1]:
-            funcs[-1] = return_function(cfg['last'])
-        else:
-            funcs[val-1] = return_function(cfg[val])
-
-    return funcs
+        return funcs
+    else:
+        raise ValueError(f"Unrecognised argument {cfg} for 'activation_funcs'!")
 
 # -----------------------------------------------------------------------------
 # -- Neural net class ---------------------------------------------------------
diff --git a/model_plots/HarrisWilson/prob_density.py b/model_plots/HarrisWilson/prob_density.py
index 950205e..e78dfaf 100644
--- a/model_plots/HarrisWilson/prob_density.py
+++ b/model_plots/HarrisWilson/prob_density.py
@@ -3,19 +3,30 @@ from utopya.plotting import is_plot_func, PlotHelper
 log = logging.getLogger(__name__)
 import matplotlib.pyplot as plt
 import matplotlib.lines as mlines
+import scipy.ndimage
 
 @is_plot_func(use_dag=True, required_dag_tags=('data',))
 def plot_prob_density(data,
                       hlpr: PlotHelper,
                       *,
                       info_box_labels: list = None,
+                      smooth_kwargs: dict,
                       **plot_kwargs):
 
     dset = data.pop('data')
+    smooth, sigma = smooth_kwargs.pop('enabled', False), smooth_kwargs.pop('sigma', None)
 
     # 1d: plot a single probability density
-    if not isinstance(data, dict):
-        hlpr.ax.plot(dset['data']['param1'], data['data']['data']['prob'], **plot_kwargs)
+    if not isinstance(dset, dict):
+
+        y_vals = dset['prob']
+
+        # Smooth the probability distribution, if set
+        if smooth:
+            y_vals = scipy.ndimage.gaussian_filter1d(y_vals, sigma, **smooth_kwargs)
+
+        # Plot the distribution
+        hlpr.ax.plot(dset['param1'], y_vals, **plot_kwargs)
 
     # 2d: plot stacked densities
     else:
@@ -24,8 +35,15 @@ def plot_prob_density(data,
 
         for i, key in enumerate(dsets):
 
+            y_vals = dsets[key]['prob']
+
+            # Smooth the probability distribution, if set
+            if smooth:
+                s = sigma[i] if isinstance(sigma, list) else sigma
+                y_vals = scipy.ndimage.gaussian_filter1d(y_vals, sigma, **smooth_kwargs)
+
             # Plot the probability distribution
-            hlpr.ax.plot(dsets[key]['param1'], dsets[key]['prob'], label = f"{dset['param']} = {key}", **plot_kwargs)
+            hlpr.ax.plot(dsets[key]['param1'], y_vals, label = f"{dset['param']} = {key}", **plot_kwargs)
 
     # Plot the textbox
     if info_box_labels:
diff --git a/model_plots/SIR/scatter.py b/model_plots/SIR/scatter.py
index 955a17c..b141ac7 100644
--- a/model_plots/SIR/scatter.py
+++ b/model_plots/SIR/scatter.py
@@ -1,22 +1,21 @@
 import matplotlib.colors as mcolors
-import numpy as np
 from typing import Union
 from utopya.plotting import is_plot_func, PlotHelper
 from dantro.plot.utils import ColorManager
 
-@is_plot_func(use_dag=True, supports_animation=True)
-def scatter( *,
-             hlpr: PlotHelper,
-             data: dict,
-             cmap: Union[str, dict, mcolors.Colormap] = None,
-             norm: Union[str, dict, mcolors.Normalize] = None,
-             vmin: float = None,
-             vmax: float = None,
-             labels: dict = None,
-             add_colorbar: bool = True,
-             cbar_kwargs: dict = None,
-             **plot_kwargs):
 
+@is_plot_func(use_dag=True, supports_animation=True)
+def scatter(*,
+            hlpr: PlotHelper,
+            data: dict,
+            cmap: Union[str, dict, mcolors.Colormap] = None,
+            norm: Union[str, dict, mcolors.Normalize] = None,
+            vmin: float = None,
+            vmax: float = None,
+            add_colorbar: bool = True,
+            cbar_kwargs: dict = None,
+            frames_isel: list = None,
+            **plot_kwargs):
     """ Plots an animation of the agents in space, colored by their 'kind'.
 
     :param hlpr: the PlotHelper
@@ -28,9 +27,6 @@ def scatter( *,
            Ignored if norm is *BoundaryNorm*.
     :param vmax (float, optional): The upper bound of the color-mapping.
            Ignored if norm is *BoundaryNorm*.
-    :param labels (Union[dict, list], optional): Colorbar tick-labels keyed by
-           tick position. If a list of labels is passed they are
-           automatically assigned to the positions [0, 1, 2, ...].
     :param add_colorbar (bool, optional): Whether to add a colorbar
     :param cbar_kwargs (dict, optional): Arguments for colorbar creation.
     :param **plot_kwargs: Passed on to :py:func:`matplotlib.axes.Axes.scatter`
@@ -47,29 +43,30 @@ def scatter( *,
     # Plot the image
     im = hlpr.ax.scatter(data['data'][{'time': 0, 'coords': 0}]['position'],
                          data['data'][{'time': 0, 'coords': 1}]['position'],
-                         c=data['data'][{'time': 0}]['kinds'], cmap=cm.cmap, **plot_kwargs)
+                         c=data['data'][{'time': 0}]['kinds'],
+                         cmap=cm.cmap,
+                         norm=cm.norm,
+                         **plot_kwargs)
+
     hlpr.ax.set_aspect("equal")
 
     # Add the Colorbar, if specified
     if add_colorbar:
-        cb = cm.create_cbar(
+        cm.create_cbar(
             im,
             fig=hlpr.fig,
             ax=hlpr.ax,
             **(cbar_kwargs if cbar_kwargs else {}),
         )
-        if labels:
-            cb.set_ticks(list(labels.keys()))
-            cb.set_ticklabels(list(labels.values()))
+
+    frames_isel = frames_isel if frames_isel is not None else data['data'].coords['time']
 
     # Animation update function
     def update():
-        for t in data['data'].coords['time']:
-
-            im.set_offsets(data['data'][{'time': t.values-1}]['position'])
-            im.set_array(data['data'][{'time': t.values-1}]['kinds'].values.flatten())
-
+        for t in frames_isel:
+            im.set_offsets(data['data']['position'].sel({'time': t}))
+            im.set_array(data['data']['kinds'].sel({'time': t}).values.flatten())
             yield
 
     # Register the animation
-    hlpr.register_animation_update(update)
\ No newline at end of file
+    hlpr.register_animation_update(update)
diff --git a/models/HarrisWilson/HarrisWilson_base_plots.yml b/models/HarrisWilson/HarrisWilson_base_plots.yml
index 527a707..4e1f84a 100644
--- a/models/HarrisWilson/HarrisWilson_base_plots.yml
+++ b/models/HarrisWilson/HarrisWilson_base_plots.yml
@@ -196,7 +196,7 @@ loss_density_3d:
       rotate_z_label: False
 
 # -- Extracted probability densities  ----------------------------------------------------------------------------------
-prob_density:
+marginals:
   based_on: .creator.multiverse
   expected_multiverse_ndim: [1,2,3,4,5]
   module: model_plots.HarrisWilson
@@ -222,13 +222,9 @@ prob_density:
       kwargs:
         bins: 1000
       tag: data
-  helpers:
-    set_labels:
-      y: '$-\log_{10}(J)$'
-
 
-prob_density_stacked:
-  based_on: prob_density
+marginals_stacked:
+  based_on: marginals
   expected_multiverse_ndim: [2,3,4,5]
   transform:
     - xr.Dataset:
@@ -242,7 +238,4 @@ prob_density_stacked:
         along_dim: sigma
         bins: 1000
       tag: data
-  linewidth: 1
-  helpers:
-    set_labels:
-      y: '$\exp(-\log_{10}(J))/Z$'
\ No newline at end of file
+  linewidth: 1
\ No newline at end of file
diff --git a/models/HarrisWilson/HarrisWilson_cfg.yml b/models/HarrisWilson/HarrisWilson_cfg.yml
index afd80ed..548f321 100644
--- a/models/HarrisWilson/HarrisWilson_cfg.yml
+++ b/models/HarrisWilson/HarrisWilson_cfg.yml
@@ -40,7 +40,7 @@ NeuralNet:
   num_layers: !is-positive-int 6
   nodes_per_layer: !is-positive-int 20
   activation_funcs:
-    last: abs
+    -1: abs
   bias: !is-bool True
   init_bias: [0, 4]
   learning_rate: !is-positive 0.002
diff --git a/models/HarrisWilson/HarrisWilson_plots.yml b/models/HarrisWilson/HarrisWilson_plots.yml
index d92c422..9efb076 100644
--- a/models/HarrisWilson/HarrisWilson_plots.yml
+++ b/models/HarrisWilson/HarrisWilson_plots.yml
@@ -168,39 +168,42 @@ loss_density/alpha_beta:
 #  file_ext: png
 
 ## Plot the estimated probability density over a single parameter
-prob_density/alpha:
-  based_on: prob_density
+marginals/alpha:
+  based_on: marginals
   select_and_combine:
     fields:
       param1: alpha
   helpers:
     set_labels:
       x: '$\alpha$'
+      y: '$\rho(\alpha)$'
     set_limits:
       x: [0, 2]
 
-prob_density/beta:
-  based_on: prob_density
+marginals/beta:
+  based_on: marginals
   select_and_combine:
     fields:
       param1: beta
   helpers:
     set_labels:
       x: '$\beta$'
+      y: '$\rho(\beta)$'
 
-prob_density/kappa:
-  based_on: prob_density
+marginals/kappa:
+  based_on: marginals
   select_and_combine:
     fields:
       param1: kappa
   helpers:
     set_labels:
       x: '$\kappa$'
+      y: '$\rho(\kappa)$'
 
-prob_density/alpha_stacked:
+marginals/alpha_stacked:
   based_on:
-    - prob_density/alpha
-    - prob_density_stacked
+    - marginals/alpha
+    - marginals_stacked
   style:
     figure.figsize: [ *half_width, *quarter_width ]
   helpers:
@@ -211,10 +214,10 @@ prob_density/alpha_stacked:
       custom_labels:  ['temporal', 'spatial']
   info_box_labels: ['$\hat{\alpha}_t$', '$\hat{\alpha}_s$']
 
-prob_density/beta_stacked:
+marginals/beta_stacked:
   based_on:
-    - prob_density/beta
-    - prob_density_stacked
+    - marginals/beta
+    - marginals_stacked
   style:
     figure.figsize: [ *half_width, *quarter_width ]
   helpers: 
@@ -222,10 +225,10 @@ prob_density/beta_stacked:
       use_legend: False
   info_box_labels: ['$\hat{\beta}_t$', '$\hat{\beta}_s$']
 
-prob_density/kappa_stacked:
+marginals/kappa_stacked:
   based_on:
-    - prob_density/kappa
-    - prob_density_stacked
+    - marginals/kappa
+    - marginals_stacked
   style:
     figure.figsize: [ *half_width, *quarter_width ]
   info_box_labels: ['$\hat{\kappa}_t$', '$\hat{\kappa}_s$']
diff --git a/models/HarrisWilson/cfgs/London_dataset/eval.yml b/models/HarrisWilson/cfgs/London_dataset/eval.yml
index 463281d..298e82b 100644
--- a/models/HarrisWilson/cfgs/London_dataset/eval.yml
+++ b/models/HarrisWilson/cfgs/London_dataset/eval.yml
@@ -25,8 +25,8 @@ _:
 
 .defaults:
   based_on:
-    - prob_density
-    - prob_density_stacked
+    - marginals
+    - marginals_stacked
   file_ext: pdf
   style:
     figure.figsize: [ *half_width, *quarter_width ]
diff --git a/models/HarrisWilson/cfgs/Loss_landscape/eval.yml b/models/HarrisWilson/cfgs/Loss_landscape/eval.yml
index bc4c44a..20f1858 100644
--- a/models/HarrisWilson/cfgs/Loss_landscape/eval.yml
+++ b/models/HarrisWilson/cfgs/Loss_landscape/eval.yml
@@ -11,8 +11,8 @@ _:
 
 .defaults:
   based_on:
-    - prob_density
-    - prob_density_stacked
+    - marginals
+    - marginals_stacked
   file_ext: pdf
   style:
     figure.figsize: [ *half_width, *quarter_width ]
diff --git a/models/HarrisWilson/cfgs/Marginals/eval.yml b/models/HarrisWilson/cfgs/Marginals/eval.yml
index 0f5a662..420dc2a 100644
--- a/models/HarrisWilson/cfgs/Marginals/eval.yml
+++ b/models/HarrisWilson/cfgs/Marginals/eval.yml
@@ -27,8 +27,8 @@ _:
 
 .defaults:
   based_on:
-    - prob_density
-    - prob_density_stacked
+    - marginals
+    - marginals_stacked
   file_ext: pdf
   style:
     figure.figsize: [ *half_width, *fifth_width ]
diff --git a/models/SIR/ABM.py b/models/SIR/ABM.py
index a1c8960..528d5a6 100644
--- a/models/SIR/ABM.py
+++ b/models/SIR/ABM.py
@@ -1,5 +1,5 @@
+import copy
 from enum import IntEnum
-from typing import Union
 import torch
 import math
 import numpy as np
@@ -35,8 +35,11 @@ class Vector:
     def __mul__(self, other):
         return self.x * other.x + self.y * other.y
 
+    def __mod__(self, other):
+        return Vector(x=self.x % other.x, y=self.y % other.y)
+
     def __repr__(self) -> str:
-        return f'{self.x}, {self.y}'
+        return f'({self.x}, {self.y})'
 
     def __sub__(self, other):
         return Vector(x=self.x - other.x, y=self.y - other.y)
@@ -52,35 +55,38 @@ class Vector:
         self.y *= f
         return self
 
-    def within_space(self, space) -> bool:
+    def withinspace(self, space) -> bool:
         # Checks whether the vector lies within a square domain
         return (0 < self.x < space.x) and (0 < self.y < space.y)
 
 
-def distance(v: Vector, w: Vector):
-    """ Returns the distance between two vectors v and w"""
-    return abs(v - w)
+def distance(v: Vector, w: Vector, *, periodic: bool, space: Vector = None, as_tensor: bool = True):
+    """ Returns the distance between two vectors v and w. If the space is periodic, the distance is
+    calculated accordingly."""
+    if not periodic:
+        return abs(v - w) if not as_tensor else torch.tensor(abs(v - w), dtype=torch.float)
+    else:
+        d = v-w
+        dist = math.sqrt(pow(min(abs(d.x), abs(d.x - space.x)), 2) + pow(min(abs(d.y), abs(d.y-space.y)), 2))
+
+        return dist if not as_tensor else torch.tensor(dist, dtype=torch.float)
 
 
 # --- The agent class --------------------------------------------------------------------------------------------------
 class Agent:
 
-    def __init__(self, *, id: int, kind: kinds, position: Vector, time_since_infection: int = 0):
+    def __init__(self, *, id: int, kind: kinds, position: Vector):
         """
 
         :param id: the agent id (fixed)
         :param kind: the agent kind
         :param pos: the agent position
-        :param time_since_infection: the time since the agent was infected
         """
         self.id = id
         self.kind = kind
         self.position = position
-        self.time_since_infection = time_since_infection
-
-    # Set the 'kind' variable of an agent
-    def set_kind(self, new_kind):
-        self.kind = new_kind
+        self.init_position = position
+        self.init_kind = kind
 
     # Move an agent along a direction vector
     def move(self, direction: Vector):
@@ -88,7 +94,7 @@ class Agent:
 
     # Moves an agent within a square domain, repelling it from the boundary walls
     def repel_from_wall(self, direction: Vector, space: Vector):
-        if not (self.position + direction).within_space(space):
+        if not (self.position + direction).withinspace(space):
             new_pos = self.position + direction
             if new_pos.x <= 0:
                 direction.x = - (direction.x + 2 * self.position.x)
@@ -100,7 +106,10 @@ class Agent:
                 direction.y = - (direction.y - 2 * (space.y - self.position.y))
         self.move(direction)
 
-    def move_randomly_in_space(self, *, space: Vector, diffusion: float, periodic: bool = False):
+    def move_in_periodic_space(self, direction: Vector, space: Vector):
+        self.position = (self.position + direction) % space
+
+    def move_randomly_inspace(self, *, space: Vector, diffusion: float, periodic: bool = False):
         """Move an agent randomly within a space with a given diffusivity. If the boundaries are periodic,
         the agent moves through the boundaries
 
@@ -117,13 +126,18 @@ class Agent:
         if not periodic:
             self.repel_from_wall(direction, space)
 
-        # TODO: Implement periodic boundaries
         # Periodic case: move through boundaries
         else:
-            self.move(direction)
+            self.move_in_periodic_space(direction, space)
 
-    def increase_time_since_infection(self):
-        self.time_since_infection += 1
+    def reset(self):
+        self.position = self.init_position
+        self.kind = self.init_kind
+
+    def __repr__(self):
+        return f'Agent {self.id}; ' \
+               f'kind: {self.kind}; ' \
+               f'position: {self.position}; '
 
 
 # --- The SIR ABM ------------------------------------------------------------------------------------------------------
@@ -136,10 +150,10 @@ class SIR_ABM:
                  sigma_s: float,
                  sigma_i: float,
                  sigma_r: float,
-                 dt: float,
                  r_infectious: float,
                  p_infect: float,
                  t_infectious: float,
+                 is_periodic: bool,
                  **__):
         """
 
@@ -149,64 +163,64 @@ class SIR_ABM:
         """
 
         # Parameters for the dynamics
-        self._space = Vector(x=space[0], y=space[1])
-        self._sigma_s = sigma_s
-        self._sigma_i = sigma_i
-        self._sigma_r = sigma_r
-        self._r_infectious = r_infectious
-        self._p_infect = p_infect
-        self._t_infectious = t_infectious
-        self._dt = dt
+        self.space = Vector(x=space[0], y=space[1])
+        self.is_periodic = is_periodic
+        self.sigma_s = sigma_s
+        self.sigma_i = sigma_i
+        self.sigma_r = sigma_r
+        self.r_infectious = torch.tensor(r_infectious)
+        self.p_infect = torch.tensor(p_infect)
+        self.t_infectious = torch.tensor(t_infectious)
 
         # Set up the cells and initialise their location at a random position in space.
         # All cells are initialised as susceptible
         self.N = N
+        self.init_kinds = [kinds.INFECTED] + [kinds.SUSCEPTIBLE] * (self.N - 1)
 
         # Initialise the agent positions and kinds
-        self.agents = None
+        self.agents = {i: Agent(id=i,
+                                kind=self.init_kinds[i],
+                                position=Vector(x=np.random.rand() * self.space.x,
+                                                y=np.random.rand() * self.space.y))
+                       for i in range(self.N)}
+
+        # Track the ids of the susceptible, infected, and recovered cells
         self.kinds = None
-        self.current_positions = None
+
+        # Track the current kinds, positions, and total kind counts of all the agents
         self.current_kinds = None
+        self.current_positions = None
         self.current_counts = None
+
+        # Count the number of susceptible, infected, and recovered agents.
         self.susceptible = None
         self.infected = None
         self.recovered = None
-        self.initialise()
 
-    def initialise(self):
+        # Track the times since infection occurred for each agent. Index = time since infection
+        self.times_since_infection = None
 
-        self.agents = {i: Agent(id=i,
-                                kind=kinds.SUSCEPTIBLE,
-                                position=Vector(x=np.random.rand() * self._space.x,
-                                                y=np.random.rand() * self._space.y),
-                                time_since_infection=0)
-                       for i in range(self.N)}
+        # Initialise all the datasets
+        self.initialise()
 
-        # Initialise a single agent as infected
-        self.agents[0].kind = kinds.INFECTED
-        self.agents[1].kind = kinds.RECOVERED
+    # Initialises the ABM data containers
+    def initialise(self):
 
-        # Track the ids of the susceptible, infected, and recovered cells
-        self.kinds = {kinds.SUSCEPTIBLE: {i: None for i in range(2, self.N)},
+        # Initialise the ABM with one infected agent.
+        self.kinds = {kinds.SUSCEPTIBLE: {i: None for i in range(1, self.N)},
                       kinds.INFECTED: {0: None},
-                      kinds.RECOVERED: {1: None}}
-
-        # Track the current positions and kinds of all the cells
-        self.current_positions = [(self.agents[i].position.x, self.agents[i].position.y) for i in range(self.N)]
+                      kinds.RECOVERED: {}}
         self.current_kinds = [[int(self.agents[i].kind)] for i in range(self.N)]
-        self.current_counts = [[len(self.kinds[kinds.SUSCEPTIBLE])],
-                               [len(self.kinds[kinds.INFECTED])],
-                               [len(self.kinds[kinds.RECOVERED])]]
+        self.current_counts = torch.tensor([[self.N - 1], [1.0], [0.0]], dtype=torch.float)
+        self.susceptible = torch.tensor(self.N - 1, dtype=torch.float)
+        self.infected = torch.tensor(1, dtype=torch.float)
+        self.recovered = torch.tensor(0, dtype=torch.float)
 
-        # Count the number of susceptible, infected, and recovered agents.
-        self.susceptible = torch.tensor(len(self.kinds[kinds.SUSCEPTIBLE]), dtype=torch.float, requires_grad=True)
-        self.infected = torch.tensor(len(self.kinds[kinds.INFECTED]), dtype=torch.float, requires_grad=True)
-        self.recovered = torch.tensor(len(self.kinds[kinds.RECOVERED]), dtype=torch.float, requires_grad=True)
+        self.current_positions = [(self.agents[i].position.x, self.agents[i].position.y) for i in range(self.N)]
 
-    # Updates the agent positions
-    def update_positions(self):
+        self.times_since_infection = [[0]]
 
-        self.current_positions = [(self.agents[i].position.x, self.agents[i].position.y) for i in range(self.N)]
+    # --- Update functions ---------------------------------------------------------------------------------------------
 
     # Updates the agent kinds
     def update_kinds(self, id=None, kind=None):
@@ -216,75 +230,111 @@ class SIR_ABM:
         else:
             self.current_kinds[id] = [int(kind)]
 
-    # TODO make this a differentiable function
+    # Updates the kind counts
     def update_counts(self):
 
-        self.current_counts = [[len(self.kinds[kinds.SUSCEPTIBLE])],
-                               [len(self.kinds[kinds.INFECTED])],
-                               [len(self.kinds[kinds.RECOVERED])]]
+        self.current_counts = torch.tensor([[len(self.kinds[kinds.SUSCEPTIBLE])],
+                                            [len(self.kinds[kinds.INFECTED])],
+                                            [len(self.kinds[kinds.RECOVERED])]]).float()
+
+    # Moves the agents randomly in space
+    def move_agents_randomly(self):
+
+        for agent_id in self.kinds[kinds.SUSCEPTIBLE].keys():
+            self.agents[agent_id].move_randomly_inspace(space=self.space, diffusion=self.sigma_s,
+                                                        periodic=self.is_periodic)
+
+        for agent_id in self.kinds[kinds.INFECTED].keys():
+            self.agents[agent_id].move_randomly_inspace(space=self.space, diffusion=self.sigma_i,
+                                                        periodic=self.is_periodic)
+
+        for agent_id in self.kinds[kinds.RECOVERED].keys():
+            self.agents[agent_id].move_randomly_inspace(space=self.space, diffusion=self.sigma_r,
+                                                        periodic=self.is_periodic)
+
+    # Updates the agent positions
+    def update_positions(self):
+
+        self.current_positions = [(self.agents[i].position.x, self.agents[i].position.y) for i in range(self.N)]
 
     # Resets the ABM to the initial state
     def reset(self):
+        for i in range(self.N):
+            self.agents[i].reset()
         self.initialise()
 
-    # ------------------------------------------------------------------------------------------------------------------
-
-    def run_single(self, *, parameters: float = None):
-
-        p_infect = self._p_infect if parameters is None else parameters
-
-        """ Runs the ABM for a single iteration"""
-        # Increment the time since infection for all infected agents.
-        # Change any 'infected' agents that have surpassed the maximum infected time to 'recovered'
-        for id in list(self.kinds[kinds.INFECTED].keys()):
-
-            self.agents[id].increase_time_since_infection()
-
-            if self.agents[id].time_since_infection > self._t_infectious:
-                self.kinds[kinds.INFECTED].pop(id)
-                self.kinds[kinds.RECOVERED].update({id: None})
-
-                # Update the kinds and counts
-                self.update_kinds(id, kinds.RECOVERED)
-                self.current_counts[1][0] -= 1
-                self.current_counts[2][0] += 1
-
-        # Calculate the distances from the infected to the susceptible agents and keep only those pairs which are
-        # within the infection radius
-        if self.current_counts[1][0] != 0:
-            distances = []
-            for s in self.kinds[kinds.SUSCEPTIBLE].keys():
-                for i in self.kinds[kinds.INFECTED].keys():
-                    if distance(self.agents[s].position, self.agents[i].position) < self._r_infectious:
-                        distances.append([s, i])
-
-            if not distances:
-                pass
-
-            else:
-                # For all pairs within infection distance, infected the agent with
-                # probability p_infect
-                for s, _ in distances:
-                    if s not in self.kinds[kinds.SUSCEPTIBLE].keys():
-                        continue
-                    if np.random.rand() < p_infect:
-                        self.agents[s].kind = kinds.INFECTED
-                        self.kinds[kinds.SUSCEPTIBLE].pop(s)
-                        self.kinds[kinds.INFECTED].update({s: None})
-                        self.update_kinds(s, kinds.INFECTED)
-                        self.current_counts[0][0] -= 1
-                        self.current_counts[1][0] += 1
+    # --- Run function -------------------------------------------------------------------------------------------------
 
-        # Move the susceptible, infected, and recovered agents with their respective diffusivities
-        for id in self.kinds[kinds.SUSCEPTIBLE].keys():
-            self.agents[id].move_randomly_in_space(space=self._space, diffusion=self._sigma_s)
+    # Runs the ABM for a single iteration
+    def run_single(self, *, parameters: torch.tensor = None):
+
+        p_infect = self.p_infect if parameters is None else parameters[0]
+        t_infectious = self.t_infectious if parameters is None else parameters[1]
+
+        # Collect the ids of the infected agents
+        infected_agent_ids = []
 
-        for id in self.kinds[kinds.INFECTED].keys():
-            self.agents[id].move_randomly_in_space(space=self._space, diffusion=self._sigma_i)
+        if self.kinds[kinds.SUSCEPTIBLE] and self.kinds[kinds.INFECTED]:
 
-        for id in self.kinds[kinds.RECOVERED].keys():
-            self.agents[id].move_randomly_in_space(space=self._space, diffusion=self._sigma_r)
+            # For each susceptible agent, calculate the number of contacts to an infected agent.
+            # A contact occurs when the susceptible agent is within the infection radius of an infected agent.
+            num_contacts = torch.sum(torch.vstack([torch.hstack([
+                torch.ceil(
+                    torch.relu(1 - distance(self.agents[s].position, self.agents[i].position,
+                                            space=self.space, periodic=self.is_periodic) / self.r_infectious))
 
+                for i in self.kinds[kinds.INFECTED].keys()]) for s in self.kinds[kinds.SUSCEPTIBLE].keys()])
+                , dim=1).long()
+
+            # Get the ids of susceptible agents that had a non-zero number of contacts with infected agents
+            risk_contacts = torch.nonzero(num_contacts).long()
+
+            if len(risk_contacts) != 0:
+                # Infect all susceptible agents that were in contact with an infected agent with probability
+                # 1 - (1- p_infect)^n, where n is the number of contacts.
+                infections = torch.flatten(torch.ceil(torch.relu(
+                    (1 - torch.pow((1 - p_infect), num_contacts[risk_contacts])) - torch.rand((len(risk_contacts), 1))
+                )))
+
+                # Get the ids of the newly infected agents
+                infected_agent_ids = [
+                    list(self.kinds[kinds.SUSCEPTIBLE].keys())[_] for _ in torch.flatten(
+                        risk_contacts[torch.nonzero(infections != 0.0, as_tuple=True)]
+                    )
+                ]
+
+            if infected_agent_ids:
+
+                # Update the counts of susceptible and infected agents accordingly
+                self.current_counts[0] -= len(infected_agent_ids)
+                self.current_counts[1] += len(infected_agent_ids)
+
+                # Update the agent kind to 'infected'
+                for agent_id in infected_agent_ids:
+                    self.agents[agent_id].kind = kinds.INFECTED
+                    self.kinds[kinds.SUSCEPTIBLE].pop(agent_id)
+                    self.kinds[kinds.INFECTED].update({agent_id: None})
+                    self.update_kinds(agent_id, kinds.INFECTED)
+
+        # Track the time since infection of the newly infected agents
+        self.times_since_infection.insert(0, infected_agent_ids)
+
+        # Change any 'infected' agents that have surpassed the maximum infected time to 'recovered'.
+        if len(self.times_since_infection) > t_infectious:
+
+            # The agents that have been infectious for the maximum amount of time have recovered
+            recovered_agents = self.times_since_infection.pop()
+
+            # Update the counts accordingly
+            self.current_counts[1] -= len(recovered_agents)
+            self.current_counts[2] += len(recovered_agents)
+
+            # Update the agent kinds
+            for agent_id in recovered_agents:
+                self.kinds[kinds.INFECTED].pop(agent_id)
+                self.kinds[kinds.RECOVERED].update({agent_id: None})
+                self.update_kinds(agent_id, kinds.RECOVERED)
+
+        # Move the susceptible, infected, and recovered agents with their respective diffusivities
+        self.move_agents_randomly()
         self.update_positions()
-        # self.update_kinds()
-        # self.update_counts()
diff --git a/models/SIR/DataGeneration.py b/models/SIR/DataGeneration.py
index e69de29..ade5041 100644
--- a/models/SIR/DataGeneration.py
+++ b/models/SIR/DataGeneration.py
@@ -0,0 +1,203 @@
+import h5py as h5
+import numpy as np
+import torch
+
+from .ABM import SIR_ABM
+
+
+# --- Data generation functions ------------------------------------------------------------------------------------
+def generate_data_from_ABM(*, cfg: dict, parameters=None,
+                           positions=None,
+                           kinds=None,
+                           counts=None):
+    """
+    Runs the ABM for n iterations and writes out the data. If the 'type' is 'training',
+    the kinds, positions, and counts are written out and stored. If the 'type' is 'prediction',
+    only the predicted counts are written out.
+    """
+    print(f'\n   Initialising the ABM ... ')
+    ABM = SIR_ABM(**cfg)
+    num_steps: int = cfg['num_steps']
+    data = torch.empty((num_steps, 3, 1), dtype=torch.float)
+    parameters = torch.tensor([ABM.p_infect, ABM.t_infectious]) if parameters is None else parameters
+
+    print(f'\n   Generating synthetic data ... ')
+    for _ in range(num_steps):
+
+        # Run the ABM for a single step
+        ABM.run_single(parameters=parameters)
+
+        # Get the densities
+        densities = ABM.current_counts.float() / ABM.N
+
+        # Write out the new positions
+        if positions:
+            positions.resize(positions.shape[0] + 1, axis=0)
+            positions[-1, :, :] = ABM.current_positions
+
+        # Write out the new kinds
+        if kinds:
+            kinds.resize(kinds.shape[0] + 1, axis=0)
+            kinds[-1, :] = ABM.current_kinds
+
+        # Write out the new counts
+        if counts:
+            counts.resize(counts.shape[0] + 1, axis=0)
+            counts[-1, :] = densities
+
+        # Append the new counts to training dataset
+        data[_] = densities
+
+        print(f'   Completed run {_} of {num_steps} ... ')
+
+    return data
+
+
+def generate_smooth_data(*, cfg: dict = None, num_steps: int = None, parameters=None, init_state, counts=None,
+                         write_init_state: bool = True, requires_grad: bool = False):
+    """
+    Generates a dataset of SIR-counts by iteratively solving the system of differential equations.
+    """
+    num_steps: int = cfg['num_steps'] if num_steps is None else num_steps
+    data = torch.empty((num_steps, 3, 1), dtype=torch.float) if not write_init_state else torch.empty(
+        (num_steps + 1, 3, 1), dtype=torch.float)
+    parameters = torch.tensor([cfg['p_infect'], cfg['t_infectious'], cfg['sigma']], dtype=torch.float) if parameters is None else parameters
+
+    # Write out the initial state if required
+    if write_init_state and counts:
+        data[0] = init_state
+        counts.resize(counts.shape[0] + 1, axis=0)
+        counts[-1, :] = init_state
+
+    current_state = init_state.clone()
+    current_state.requires_grad = requires_grad
+
+    for _ in range(num_steps):
+
+        # Generate the transformation matrix
+        # Patients only start recovering after a certain time
+        w = torch.normal(torch.tensor(0.0), torch.tensor(1.0))
+        tau = 1 / parameters[1] * torch.sigmoid(1000 * (_ / parameters[1] - 1))
+        matrix = torch.vstack([torch.tensor([-parameters[0], -parameters[2] * w]),
+                               torch.tensor([parameters[0], -tau + parameters[2] * w]),
+                               torch.tensor([0, tau])])
+
+        current_state = torch.relu(current_state + torch.matmul(
+            matrix,
+            torch.vstack([current_state[0] * current_state[1], current_state[1]])
+        ))
+
+        if write_init_state:
+            data[_+1] = current_state
+        else:
+            data[_] = current_state
+
+        if counts:
+            counts.resize(counts.shape[0] + 1, axis=0)
+            counts[-1, :] = current_state
+
+    return data
+
+
+def get_SIR_data(*, data_cfg: dict, h5group: h5.Group):
+    """ Returns the training data for the SIR model. If a directory is passed, the
+        data is loaded from that directory. Otherwise, synthetic training data is generated, either from an ABM,
+        or by iteratively solving the temporal ODE system.
+    """
+    if 'load_from_dir' in data_cfg.keys():
+
+        with h5.File(data_cfg['load_from_dir'], "r") as f:
+
+            data = np.array(f['SIR']['true_counts'])
+
+            dset_true_counts = h5group.create_dataset(
+                "true_counts",
+                (len(data), 3, 1),
+                maxshape=(None, 3, 1),
+                chunks=True,
+                compression=3,
+                dtype=float
+            )
+
+            dset_true_counts.attrs['dim_names'] = ['time', 'kind', 'kinds']
+            dset_true_counts.attrs['coords_mode__time'] = "trivial"
+            dset_true_counts.attrs['coords_mode__kind'] = 'values'
+            dset_true_counts.attrs['coords__kind'] = ['susceptible', 'infected', 'recovered']
+            dset_true_counts.attrs['coords_mode__kinds'] = 'values'
+            dset_true_counts.attrs['coords__kinds'] = ['kind']
+
+            dset_true_counts[:, :, :] = data
+
+            return torch.from_numpy(data).float()
+
+    elif 'synthetic_data' in data_cfg.keys():
+
+        # True counts
+        dset_true_counts = h5group.create_dataset(
+            "true_counts",
+            (0, 3, 1),
+            maxshape=(None, 3, 1),
+            chunks=True,
+            compression=3,
+            dtype=float
+        )
+
+        dset_true_counts.attrs['dim_names'] = ['time', 'kind', 'kinds']
+        dset_true_counts.attrs['coords_mode__time'] = "trivial"
+        dset_true_counts.attrs['coords_mode__kind'] = 'values'
+        dset_true_counts.attrs['coords__kind'] = ['susceptible', 'infected', 'recovered']
+        dset_true_counts.attrs['coords_mode__kinds'] = 'values'
+        dset_true_counts.attrs['coords__kinds'] = ['kind']
+
+        # --- Generate the data ----------------------------------------------------------------------------------------
+        type = data_cfg['synthetic_data'].pop('type')
+
+        if type == 'smooth':
+            N = data_cfg['synthetic_data']['N']
+            init_state = torch.tensor([[N - 1], [1], [0]], dtype=torch.float) / N
+            training_data = generate_smooth_data(cfg=data_cfg['synthetic_data'], init_state=init_state,
+                                                 counts=dset_true_counts)
+
+        elif type == 'from_ABM':
+
+            N = data_cfg['synthetic_data']['N']
+
+            # Initialise agent position dataset
+            dset_position = h5group.create_dataset(
+                "position",
+                (0, N, 2),
+                maxshape=(None, N, 2),
+                chunks=True,
+                compression=3,
+            )
+            dset_position.attrs['dim_names'] = ['time', 'agent_id', 'coords']
+            dset_position.attrs["coords_mode__time"] = "trivial"
+            dset_position.attrs["coords_mode__agent_id"] = "trivial"
+            dset_position.attrs["coords_mode__coords"] = "values"
+            dset_position.attrs["coords__coords"] = ["x", "y"]
+
+            # Initialise agent kind dataset
+            dset_kinds = h5group.create_dataset(
+                "kinds",
+                (0, N, 1),
+                maxshape=(None, N, 1),
+                chunks=True,
+                compression=3,
+            )
+            dset_kinds.attrs['dim_names'] = ['time', 'agent_id', 'kind']
+            dset_kinds.attrs["coords_mode__time"] = "trivial"
+            dset_kinds.attrs["coords_mode__agent_id"] = "trivial"
+            dset_kinds.attrs["coords_mode__kind"] = "values"
+            dset_kinds.attrs["coords__kind"] = ["kind"]
+
+            training_data = generate_data_from_ABM(cfg=data_cfg['synthetic_data'],
+                                                   positions=dset_position,
+                                                   kinds=dset_kinds,
+                                                   counts=dset_true_counts)
+        else:
+            raise ValueError(f"Unrecognised arugment {type}! 'Type' must be one of 'smooth' or 'from_ABM'!")
+
+        return training_data
+
+    else:
+        raise ValueError(f"You must supply one of 'load_from_dir' or 'synthetic data' keys!")
diff --git a/models/SIR/SIR_base_plots.yml b/models/SIR/SIR_base_plots.yml
index 5c3e6db..3468224 100644
--- a/models/SIR/SIR_base_plots.yml
+++ b/models/SIR/SIR_base_plots.yml
@@ -16,7 +16,7 @@
 
   page_widths:
     full_width:     &full_width       7.516
-    half_width:     &half_width       !expr 7.516 / 3
+    half_width:     &half_width       !expr 7.516 / 2
     third_width:    &third_width      !expr 7.516 / 3
     quarter_width:  &quarter_width    !expr 7.516 / 4
     fifth_width:    &fifth_width      !expr 7.516 / 5
@@ -108,24 +108,17 @@ state:
       tag: data
 
   # Colorbar settings
-  cmap: &cmap
-    from_values:
-      0: *lightgreen
-      1: *red
-      2: *darkgreen
+  cmap:
+    susceptible: *lightgreen
+    infected: *red
+    recovered: *darkgreen
   cbar_kwargs:
     shrink: 0.8
-  labels:
-    0.333: 'susceptible'
-    1: 'infected'
-    1.666: 'recovered'
-
   style:
     savefig.bbox: ~
     axes.grid: True
     axes.spines.top: True
     axes.spines.right: True
-
   # Animation control
   animation:
     writer_kwargs:
@@ -172,4 +165,78 @@ predictions:
     figure.figsize: [ *half_width, *half_width ]
   helpers:
     set_labels:
-      x: iteration
\ No newline at end of file
+      x: iteration
+#    set_scales:
+#      x: log
+
+# Two-dimensional density
+loss_density:
+  based_on:
+    - .creator.universe
+    - .plot.facet_grid.scatter
+  style:
+    figure.figsize: [ *half_width, *fifth_width ]
+  select:
+    param1:
+      path: predicted_infection_rate
+      transform:
+        - .squeeze_with_drop: [!dag_prev ]
+    loss:
+      path: loss
+      transform:
+        - np.maximum: [!dag_prev , *loss_limit]
+        - log10: [!dag_prev ]
+        - mul: [!dag_prev , -1]
+  transform:
+    - xr.Dataset:
+      kwargs:
+        data_vars:
+          param1: !dag_tag param1
+          loss: !dag_tag loss
+      tag: data
+  x: param1
+  hue: loss
+  y: loss
+  s: 1
+  add_guide: False
+  cmap:
+    continuous: true
+    from_values:
+      0: *yellow
+      1: *darkblue
+  helpers:
+    set_labels:
+      y: &loss_label '$-\log_{10}(J)$'
+
+marginals:
+  based_on: .creator.universe
+  module: model_plots.HarrisWilson
+  plot_func: plot_prob_density
+  style:
+    figure.figsize: [ *half_width, *half_width ]
+  select:
+    param1:
+      path: predicted_infection_rate
+      transform:
+        - .squeeze_with_drop: [ !dag_prev ]
+    loss:
+      path: loss
+      transform:
+        - np.maximum: [ !dag_prev , *loss_limit ]
+        - log10: [ !dag_prev ]
+        - mul: [ !dag_prev , -1 ]
+        - np.exp: [!dag_prev ]
+  transform:
+    - xr.Dataset:
+      kwargs:
+        data_vars:
+          param1: !dag_tag param1
+          loss: !dag_tag loss
+    - HarrisWilson.get_marginals: [ !dag_prev ]
+      kwargs:
+        bins: 200
+      tag: data
+  color: *darkblue
+  smooth_kwargs:
+    enabled: true
+    sigma: 2.0
diff --git a/models/SIR/SIR_cfg.yml b/models/SIR/SIR_cfg.yml
index 6ce1dd5..3238232 100644
--- a/models/SIR/SIR_cfg.yml
+++ b/models/SIR/SIR_cfg.yml
@@ -1,23 +1,36 @@
 Data:
-  N: !is-positive-int 150
-  space: [10, 10]
-  r_infectious: !is-positive 1.0
-  p_infect: !is-probability 0.5
-  t_infectious: !is-positive 30
-  sigma_s: !is-positive 0.15
-  sigma_i: !is-positive 0.03
-  sigma_r: !is-positive 0.15
-  dt: !is-positive 0.01
-  num_steps: 200
+  synthetic_data:
+    type: from_ABM
+    N: !is-positive-int 150
+    space: [10, 10]
+    is_periodic: !is-bool false
+    r_infectious: !is-positive 1.0
+    p_infect: !is-probability 0.5
+    t_infectious: !is-positive 30
+    sigma_s: !param
+      default: 0.15
+      dtype: float
+      limits: [0, ~]
+    sigma_i: !param
+      default: 0.03
+      dtype: float
+      limits: [0, ~]
+    sigma_r: !param
+      default: 0.15
+      dtype: float
+      limits: [0, ~]
+    num_steps: 200
 
 NeuralNet:
-  num_layers: !is-positive-int 1
-  nodes_per_layer: !is-positive-int 2
+  num_layers: !is-positive-int 6
+  nodes_per_layer: !is-positive-int 10
   activation_funcs:
-    last: abs
-  bias: !is-bool True
-  init_bias: [0, 4]
+    -1: abs
+  bias: !is-bool False
+  init_bias: [0, 1]
   learning_rate: !is-positive 0.002
 
 Training:
-  batch_size: 1
\ No newline at end of file
+  batch_size: 1
+  to_learn: [ p_infect, t_infectious, sigma ]
+
diff --git a/models/SIR/SIR_plots.yml b/models/SIR/SIR_plots.yml
index 8246730..57d3ca6 100644
--- a/models/SIR/SIR_plots.yml
+++ b/models/SIR/SIR_plots.yml
@@ -21,7 +21,8 @@ _:
 
   # True parameters
   true_parameters:
-    p_infect:         &p_infect         0.15
+    p_infect:         &p_infect         0.3
+    t_infect:         &t_infect         14
 
 
 # ======================================================================================================================
@@ -68,8 +69,8 @@ loss:
   style:
     figure.figsize: [ *full_width, *third_width ]
 
-# Plot the parameter predictions with true values (if given)
-predictions:
+# Plot the predicted infection probability
+predictions/p_infectious:
   based_on: predictions
   helpers:
     set_hv_lines:
@@ -96,5 +97,120 @@ predictions:
             alpha: 1.0
             boxstyle: circle
             pad: 0.4
-    set_scales:
-      x: log
\ No newline at end of file
+    set_limits:
+      y: [0, 1]
+
+predictions/t_infectious:
+  based_on: predictions
+  select:
+      data:
+        path: predicted_infection_time
+        transform:
+          - .data: [ !dag_prev ]
+  helpers:
+    set_hv_lines:
+      hlines:
+        - pos: *t_infect
+          color: *yellow
+          zorder: -1
+          linestyle: dotted
+    set_labels:
+      y: ' '
+    set_legend:
+      custom_labels: ['$t_\mathrm{infect}$']
+      title: ~
+      loc: 'best'
+    set_texts:
+      texts:
+        - x: 0.33
+          y: *t_infect
+          s: '$t_i$'
+          color: *color_p_i
+          bbox:
+            <<: *textbox
+
+predictions/noise:
+  based_on: predictions
+  select:
+      data:
+        path: predicted_noise
+        transform:
+          - .data: [ !dag_prev ]
+  helpers:
+    set_labels:
+      y: ' '
+    set_legend:
+      custom_labels: ['$\sigma$']
+      title: ~
+      loc: 'best'
+
+loss_density/p_infectious:
+  based_on: loss_density
+  select:
+    param1:
+      path: predicted_infection_rate
+  helpers:
+    set_labels:
+      x: '$p_i$'
+    set_hv_lines:
+      vlines:
+        - pos: *p_infect
+          color: *red
+          zorder: 1
+          linestyle: dotted
+
+loss_density/t_infectious:
+  based_on: loss_density
+  select:
+    param1:
+      path: predicted_infection_time
+  helpers:
+    set_labels:
+      x: '$t_i$'
+    set_hv_lines:
+      vlines:
+        - pos: *t_infect
+          color: *red
+          zorder: 1
+          linestyle: dotted
+
+marginals/p_infectious:
+  based_on: marginals
+  helpers:
+    set_labels:
+      x: '$p$'
+      y: '$\rho(p)$'
+    set_hv_lines:
+      vlines:
+        - pos: *p_infect
+          color: *red
+          zorder: 1
+          linestyle: dotted
+  style:
+    figure.figsize: [*half_width, *quarter_width]
+
+marginals/t_infectious:
+  based_on: marginals/p_infectious
+  select:
+    param1:
+      path: predicted_infection_time
+  helpers:
+    set_labels:
+      x: '$\tau$'
+      y: '$\rho(\tau)$'
+    set_hv_lines:
+      vlines:
+        - pos: *t_infect
+          color: *red
+          zorder: 1
+          linestyle: dotted
+
+marginals/noise:
+  based_on: marginals/p_infectious
+  select:
+    param1:
+      path: predicted_noise
+  helpers:
+    set_labels:
+      x: '$\sigma$'
+      y: '$\rho(\sigma)$'
\ No newline at end of file
diff --git a/models/SIR/__init__.py b/models/SIR/__init__.py
index 8db5924..dd051d8 100644
--- a/models/SIR/__init__.py
+++ b/models/SIR/__init__.py
@@ -1 +1 @@
-from .ABM import SIR_ABM
+from .DataGeneration import get_SIR_data, generate_smooth_data
\ No newline at end of file
diff --git a/models/SIR/cfgs/example_run/eval.yml b/models/SIR/cfgs/example_run/eval.yml
index edae3e8..0861c51 100644
--- a/models/SIR/cfgs/example_run/eval.yml
+++ b/models/SIR/cfgs/example_run/eval.yml
@@ -1,26 +1,77 @@
-# Animated state plot
+.variables:
+  base_path:        &base_path    data/SIR
+  loss_limit:       &loss_limit   1e-15
+
+  colors: &colors
+    yellow:         &yellow           '#F5DDA9'
+    darkblue:       &darkblue         '#2F7194'
+    red:            &red              '#ec7070'
+    skyblue:        &skyblue          '#97c3d0'
+    darkgreen:      &darkgreen        '#48675A'
+    lightbrown:     &lightbrown       '#C6BFA2'
+    orange:         &orange           '#EC9F7E'
+    lightgreen:     &lightgreen       '#AFD8BC'
+    grey:           &grey             '#3D4244'
+
+  page_widths:
+    full_width:     &full_width       7.516
+    half_width:     &half_width       !expr 7.516 / 2
+    third_width:    &third_width      !expr 7.516 / 3
+    quarter_width:  &quarter_width    !expr 7.516 / 4
+    fifth_width:    &fifth_width      !expr 7.516 / 5
+
+# Snapshots of the ABM state at four different times
 state:
-  based_on: state
-  frames_isel: [101, 901, 1701, 3301]
+  based_on:
+    - state
+    - .animation.frames
+
+  frames_isel: [3, 11, 21, 31]
+  add_colorbar: False
+  style:
+    axes.grid: False
+    axes.spines.top: False
+    axes.spines.bottom: False
+    axes.spines.left: False
+    axes.spines.right: False
+    savefig.bbox: tight
+  s: 4
   helpers:
     setup_figure:
-      figsize: [8, 8]
+      figsize: [*quarter_width, *quarter_width]
     set_limits:
       x: [0, 10]
       y: [0, 10]
     set_ticks:
       x: &labels
         major:
-          locs: [0, 10]
-          labels: ['-L', '+L']
+          locs: []
+          labels: []
       y:
         <<: *labels
 
 # Densities of agent types
 densities:
-  based_on: densities_comparison
+  based_on:
+    - .creator.universe
+    - .plot.facet_grid.line
+  select:
+    data:
+      path: predicted_counts
+      transform:
+        - .sel: [ !dag_prev , { kind: [ 'susceptible', 'infected', 'recovered' ] } ]
   x: time
-  col: type
   helpers:
-    set_limits:
-      y: [0, 1]
\ No newline at end of file
+    set_title:
+      title: ~
+    set_labels:
+      x: iteration
+      y: density
+    set_legend:
+      title: ~
+      fontsize: 9
+      custom_labels: [S, I, R]
+  linewidth: 1.5
+  style:
+    figure.figsize: [*half_width, *third_width]
+
diff --git a/models/SIR/cfgs/example_run/run.yml b/models/SIR/cfgs/example_run/run.yml
index 88529ac..3a48c69 100644
--- a/models/SIR/cfgs/example_run/run.yml
+++ b/models/SIR/cfgs/example_run/run.yml
@@ -2,14 +2,17 @@ parameter_space:
   seed: 0
   num_epochs: 1
   write_start: 1
-  write_every: 50
+  write_every: 1
   SIR:
     Data:
-      N: 3000
-      r_infectious: 0.6
-      p_infect: 0.02
-      t_infectious: 20
-      sigma_s: 0.15
-      sigma_i: 0.03
-      sigma_r: 0.15
-      num_steps: 100
\ No newline at end of file
+      synthetic_data:
+        type: from_ABM
+        N: 3000
+        space: [10, 10]
+        r_infectious: 0.6
+        p_infect: 0.02
+        t_infectious: 20
+        sigma_s: 0.15
+        sigma_i: 0.03
+        sigma_r: 0.15
+        num_steps: 100
\ No newline at end of file
diff --git a/models/SIR/cfgs/marginals/eval.yml b/models/SIR/cfgs/marginals/eval.yml
index e69de29..f745d6c 100644
--- a/models/SIR/cfgs/marginals/eval.yml
+++ b/models/SIR/cfgs/marginals/eval.yml
@@ -0,0 +1,88 @@
+.variables:
+  base_path:        &base_path    data/SIR
+  loss_limit:       &loss_limit   1e-15
+
+  colors: &colors
+    yellow:         &yellow           '#F5DDA9'
+    darkblue:       &darkblue         '#2F7194'
+    red:            &red              '#ec7070'
+    skyblue:        &skyblue          '#97c3d0'
+    darkgreen:      &darkgreen        '#48675A'
+    lightbrown:     &lightbrown       '#C6BFA2'
+    orange:         &orange           '#EC9F7E'
+    lightgreen:     &lightgreen       '#AFD8BC'
+    grey:           &grey             '#3D4244'
+
+  page_widths:
+    full_width:     &full_width       7.516
+    half_width:     &half_width       !expr 7.516 / 2
+    third_width:    &third_width      !expr 7.516 / 3
+    quarter_width:  &quarter_width    !expr 7.516 / 4
+    fifth_width:    &fifth_width      !expr 7.516 / 5
+
+  p_infect: &p_infect 0.2
+  t_infect: &t_infect 20
+
+p_infectious:
+  based_on: .creator.multiverse
+  module: model_plots.HarrisWilson
+  plot_func: plot_prob_density
+  select_and_combine:
+    fields:
+      param1: predicted_infection_rate
+      loss:
+        path: loss
+        transform:
+          - np.maximum: [ !dag_prev , *loss_limit ]
+          - log10: [ !dag_prev ]
+          - mul: [ !dag_prev , -1 ]
+          - np.exp: [ !dag_prev ]
+  transform:
+    - xr.Dataset:
+      kwargs:
+        data_vars:
+          param1: !dag_tag param1
+          loss: !dag_tag loss
+    - HarrisWilson.get_marginals: [ !dag_prev ]
+      kwargs:
+        bins: 200
+        along_dim: N
+      tag: data
+  style:
+    figure.figsize: [*half_width, *quarter_width]
+  helpers:
+    set_legend:
+      use_legend: True
+      custom_labels: [ '$N=300$', '$N=1000$', '$N=3000$' ]
+      loc: 'best'
+      ncol: 1
+    set_labels:
+      x: '$p$'
+      y: '$\rho(p)$'
+    set_hv_lines:
+      vlines:
+        - pos: *p_infect
+          color: *red
+          zorder: 1
+          linestyle: dotted
+    set_limits:
+      x: [0, 1]
+
+
+t_infectious:
+  based_on: p_infectious
+  select_and_combine:
+    fields:
+      param1: predicted_infection_time
+  helpers:
+    set_labels:
+      x: '$\tau$'
+      y: '$\rho(\tau)$'
+    set_hv_lines:
+      vlines:
+        - pos: *t_infect
+          color: *red
+          zorder: 1
+          linestyle: dotted
+    set_limits:
+      x: [0, 40]
diff --git a/models/SIR/cfgs/marginals/run.yml b/models/SIR/cfgs/marginals/run.yml
index e69de29..56df136 100644
--- a/models/SIR/cfgs/marginals/run.yml
+++ b/models/SIR/cfgs/marginals/run.yml
@@ -0,0 +1,24 @@
+perform_sweep: True
+parameter_space:
+  seed: 0
+  num_epochs: 5000
+  write_start: 1
+  write_every: 50
+  SIR:
+    Data:
+      load_from_dir: !sweep
+        default: /Users/thomasgaskin/utopya_output/SIR/synthetic_data/data/uni1/data.h5
+        values: [
+          /Users/thomasgaskin/utopya_output/SIR/synthetic_data/data/uni1/data.h5,
+          /Users/thomasgaskin/utopya_output/SIR/synthetic_data/data/uni2/data.h5,
+          /Users/thomasgaskin/utopya_output/SIR/synthetic_data/data/uni3/data.h5
+        ]
+        name: N
+    NeuralNet:
+      num_layers: 4
+      nodes_per_layer: 6
+      activation_funcs:
+        last: abs
+      bias: False
+    Training:
+      batch_size: 2
\ No newline at end of file
diff --git a/models/SIR/cfgs/synthetic_data_generation/eval.yml b/models/SIR/cfgs/synthetic_data_generation/eval.yml
index e69de29..ba0b697 100644
--- a/models/SIR/cfgs/synthetic_data_generation/eval.yml
+++ b/models/SIR/cfgs/synthetic_data_generation/eval.yml
@@ -0,0 +1,47 @@
+.variables:
+  base_path:        &base_path    data/SIR
+  loss_limit:       &loss_limit   1e-15
+
+  colors: &colors
+    yellow:         &yellow           '#F5DDA9'
+    darkblue:       &darkblue         '#2F7194'
+    red:            &red              '#ec7070'
+    skyblue:        &skyblue          '#97c3d0'
+    darkgreen:      &darkgreen        '#48675A'
+    lightbrown:     &lightbrown       '#C6BFA2'
+    orange:         &orange           '#EC9F7E'
+    lightgreen:     &lightgreen       '#AFD8BC'
+    grey:           &grey             '#3D4244'
+
+  page_widths:
+    full_width:     &full_width       7.516
+    half_width:     &half_width       !expr 7.516 / 2
+    third_width:    &third_width      !expr 7.516 / 3
+    quarter_width:  &quarter_width    !expr 7.516 / 4
+    fifth_width:    &fifth_width      !expr 7.516 / 5
+
+# Densities of agent types
+densities:
+  based_on:
+    - .creator.universe
+    - .plot.facet_grid.line
+  select:
+    data:
+      path: true_counts
+      transform:
+        - .sel: [ !dag_prev , { kind: [ 'susceptible', 'infected', 'recovered' ] } ]
+  x: time
+  helpers:
+    set_title:
+      title: ~
+    set_labels:
+      x: iteration
+      y: density
+    set_legend:
+      title: ~
+      fontsize: 9
+      custom_labels: [S, I, R]
+  linewidth: 1.5
+  style:
+    figure.figsize: [*half_width, *third_width]
+
diff --git a/models/SIR/cfgs/synthetic_data_generation/run.yml b/models/SIR/cfgs/synthetic_data_generation/run.yml
index e69de29..2727773 100644
--- a/models/SIR/cfgs/synthetic_data_generation/run.yml
+++ b/models/SIR/cfgs/synthetic_data_generation/run.yml
@@ -0,0 +1,21 @@
+perform_sweep: True
+parameter_space:
+  seed: 0
+  num_epochs: 1
+  write_start: 1
+  write_every: 1
+  SIR:
+    Data:
+      synthetic_data:
+        type: from_ABM
+        N: !sweep
+          default: 3000
+          values: [300, 1000, 3000]
+        space: [10, 10]
+        r_infectious: 0.6
+        p_infect: 0.02
+        t_infectious: 20
+        sigma_s: 0.15
+        sigma_i: 0.03
+        sigma_r: 0.15
+        num_steps: 100
\ No newline at end of file
diff --git a/models/SIR/run.py b/models/SIR/run.py
index 55a4559..54f45d4 100755
--- a/models/SIR/run.py
+++ b/models/SIR/run.py
@@ -14,6 +14,7 @@ sys.path.append(up(up(up(__file__))))
 SIR = import_module_from_path(mod_path=up(up(__file__)), mod_str='SIR')
 base = import_module_from_path(mod_path=up(up(up(__file__))), mod_str='include')
 
+
 # -----------------------------------------------------------------------------
 # -- Model implementation -----------------------------------------------------
 # -----------------------------------------------------------------------------
@@ -24,17 +25,18 @@ class SIR_NN:
     """
 
     def __init__(
-        self,
-        name: str,
-        *,
-        rng: np.random.Generator,
-        h5group: h5.Group,
-        neural_net: base.NeuralNet,
-        ABM: SIR.SIR_ABM,
-        write_every: int = 1,
-        write_start: int = 1,
-        num_steps: int = 3,
-        write_time: bool = False
+            self,
+            name: str,
+            *,
+            rng: np.random.Generator,
+            h5group: h5.Group,
+            neural_net: base.NeuralNet,
+            to_learn: list,
+            true_parameters: dict,
+            write_every: int = 1,
+            write_start: int = 1,
+            num_steps: int = 3,
+            write_time: bool = False
     ):
         """Initialize the model instance with a previously constructed RNG and
         HDF5 group to write the output data to.
@@ -53,56 +55,15 @@ class SIR_NN:
         self._h5group = h5group
         self._rng = rng
 
-        self._ABM = ABM
-        self._N = ABM.N
-        self._neural_net = neural_net
-        self._neural_net.optimizer.zero_grad()
-        self._current_loss = torch.tensor(0.0, requires_grad=False)
-        self._current_predictions = torch.tensor(0.0, requires_grad=False)
+        self.neural_net = neural_net
+        self.neural_net.optimizer.zero_grad()
+        self.current_loss = torch.tensor(0.0)
 
-        # --- Set up chunked dataset to store the state data in --------------------------------------------------------
-        # --- Datasets for true values ---------------------------------------------------------------------------------
-        # Agent positions
-        self._dset_position = self._h5group.create_dataset(
-            "position",
-            (0, self._N, 2),
-            maxshape=(None, self._N, 2),
-            chunks=True,
-            compression=3,
-        )
-        self._dset_position.attrs['dim_names'] = ['time', 'agent_id', 'coords']
-        self._dset_position.attrs["coords_mode__time"] = "start_and_step"
-        self._dset_position.attrs["coords__time"] = [write_start, write_every]
-        self._dset_position.attrs["coords_mode__agent_id"] = "trivial"
-        self._dset_position.attrs["coords_mode__coords"] = "values"
-        self._dset_position.attrs["coords__coords"] = ["x", "y"]
-
-        # Agent kinds
-        self._dset_kinds = self._h5group.create_dataset(
-            "kinds",
-            (0, self._N, 1),
-            maxshape=(None, self._N, 1),
-            chunks=True,
-            compression=3,
-        )
-        self._dset_kinds.attrs['dim_names'] = ['time', 'agent_id', 'kind']
-        self._dset_kinds.attrs["coords_mode__time"] = "start_and_step"
-        self._dset_kinds.attrs["coords__time"] = [write_start, write_every]
-        self._dset_kinds.attrs["coords_mode__agent_id"] = "trivial"
-        self._dset_kinds.attrs["coords_mode__kind"] = "values"
-        self._dset_kinds.attrs["coords__kind"] = ["kind"]
-
-        # True counts
-        self._dset_true_counts = self._h5group.create_dataset(
-            "true_counts",
-            (0, 3, 1),
-            maxshape=(None, 3, 1),
-            chunks=True,
-            compression=3,
-            dtype=int
-        )
+        self.to_learn = {key: idx for idx, key in enumerate(to_learn)}
+        self.true_parameters = {key: torch.tensor(val, dtype=torch.float) for key, val in true_parameters.items()}
+        self.current_predictions = torch.tensor([0.0, 0.0, 0.0])
 
-        # --- Datasets for neural net ----------------------------------------------------------------------------------
+        # --- Set up chunked dataset to store the state data in --------------------------------------------------------
         # Predicted Counts
         self._dset_pred_counts = self._h5group.create_dataset(
             "predicted_counts",
@@ -110,8 +71,14 @@ class SIR_NN:
             maxshape=(None, 3, 1),
             chunks=True,
             compression=3,
-            dtype=int
+            dtype=float
         )
+        self._dset_pred_counts.attrs['dim_names'] = ['time', 'kind', 'kinds']
+        self._dset_pred_counts.attrs['coords_mode__time'] = "trivial"
+        self._dset_pred_counts.attrs['coords_mode__kind'] = 'values'
+        self._dset_pred_counts.attrs['coords__kind'] = ['susceptible', 'infected', 'recovered']
+        self._dset_pred_counts.attrs['coords_mode__kinds'] = 'values'
+        self._dset_pred_counts.attrs['coords__kinds'] = ['kind']
 
         # Setup chunked dataset to store the state data in
         self._dset_loss = self._h5group.create_dataset(
@@ -137,86 +104,102 @@ class SIR_NN:
             self.dset_time.attrs["coords_mode__epoch"] = "trivial"
             self.dset_time.attrs["coords_mode__training_time"] = "trivial"
 
-        for dset in [self._dset_pred_counts, self._dset_true_counts]:
-            dset.attrs['dim_names'] = ['time', 'kind', 'kinds']
-            dset.attrs['coords_mode__time'] = "start_and_step"
-            dset.attrs['coords__time'] = [write_start, write_every]
-            dset.attrs['coords_mode__kind'] = 'values'
-            dset.attrs['coords__kind'] = ['susceptible', 'infected', 'recovered']
-            dset.attrs['coords_mode__kinds'] = 'values'
-            dset.attrs['coords__kinds'] = ['kind']
-
         # Predicted infection rate
-        self._dset_p_infect = self._h5group.create_dataset(
-            "predicted_infection_rate",
-            (0, 1),
-            maxshape=(None, 1),
-            chunks=True,
-            compression=3,
-        )
-        self._dset_p_infect.attrs['dim_names'] = ['time', 'p_infect']
-        self._dset_p_infect.attrs["coords_mode__time"] = "start_and_step"
-        self._dset_p_infect.attrs["coords__time"] = [write_start, write_every]
-
-        self._write_every = write_every
-        self._write_start = write_start
-        self._num_steps = num_steps
-
-    def generate_synthetic_data(self):
-        """Generates synthetic data (consisting of positions and counts)"""
-
-        for i in range(self._num_steps):
-            self._ABM.run_single()
-
-            self._dset_position.resize(self._dset_position.shape[0] + 1, axis=0)
-            self._dset_position[-1, :, :] = self._ABM.current_positions
-
-            self._dset_kinds.resize(self._dset_kinds.shape[0] + 1, axis=0)
-            self._dset_kinds[-1, :] = self._ABM.current_kinds
-
-            self._dset_true_counts.resize(self._dset_true_counts.shape[0] + 1, axis=0)
-            self._dset_true_counts[-1, :] = self._ABM.current_counts
+        dsets = []
+        if 'p_infect' in self.to_learn.keys():
+            self._dset_p_infect = self._h5group.create_dataset(
+                "predicted_infection_rate",
+                (0, 1),
+                maxshape=(None, 1),
+                chunks=True,
+                compression=3,
+            )
+            self._dset_p_infect.attrs['dim_names'] = ['time', 'p_infect']
+            dsets.append(self._dset_p_infect)
 
-        self._ABM.reset()
+        if 't_infectious' in self.to_learn.keys():
+            self._dset_t_infect = self._h5group.create_dataset(
+                "predicted_infection_time",
+                (0, 1),
+                maxshape=(None, 1),
+                chunks=True,
+                compression=3,
+            )
+            self._dset_t_infect.attrs['dim_names'] = ['time', 't_infectious']
+            dsets.append(self._dset_t_infect)
 
-    def generate_prediction(self):
-        """Generates synthetic data (consisting of positions and counts)"""
+        if 'sigma' in self.to_learn.keys():
+            self._dset_noise = self._h5group.create_dataset(
+                "predicted_noise",
+                (0, 1),
+                maxshape=(None, 1),
+                chunks=True,
+                compression=3,
+            )
+            self._dset_noise.attrs['dim_names'] = ['time', 'noise']
+            dsets.append(self._dset_noise)
 
-        for i in range(self._num_steps):
-            self._ABM.run_single(parameters = self._current_predictions)
+        for dset in dsets:
+            dset.attrs["coords_mode__time"] = "start_and_step"
+            dset.attrs["coords__time"] = [write_start, write_every]
 
-            self._dset_pred_counts.resize(self._dset_pred_counts.shape[0] + 1, axis=0)
-            self._dset_pred_counts[-1, :] = self._ABM.current_counts
+        self.dsets = dsets
 
-        self._ABM.reset()
+        self._write_every = write_every
+        self._write_start = write_start
+        self._num_steps = num_steps
 
-    def epoch(self, *, training_data = None, batch_size: int):
+    def epoch(self, *, training_data: torch.tensor, batch_size: int):
 
         """ Trains the model for a single epoch """
-
-        for it in range(self._num_steps):
-
-            loss = torch.tensor(1.0, requires_grad=True)
-
-            predicted_parameters = torch.tensor(self._ABM._p_infect) #self._neural_net(training_data[it:it+batch_size])
-            # pred_counts = torch.tensor(..., requires_grad=True)
-
-            self._ABM.run_single(parameters = predicted_parameters)
-                # pred_counts.append(self._ABM.current_counts)
-
-            # loss = torch.mse_loss(pred_counts, training_data[it:it+b])
-            # loss.backward()
-            # self._neural_net.optimizer.step()
-            # self._neural_net.optimizer.zero_grad()
-
-            self._current_loss = loss.clone().detach().numpy().item()
-            self._current_predictions = predicted_parameters.clone().detach()
+        for s in range(1, self._num_steps - batch_size):
+
+            predicted_parameters = self.neural_net(torch.flatten(training_data[s]))
+
+            # Get the parameters: infection rate, recovery time, noise variance
+            p = predicted_parameters[self.to_learn['p_infect']] if 'p_infect' in self.to_learn.keys() \
+                else self.true_parameters['p_infect']
+            t = 10*predicted_parameters[self.to_learn['t_infectious']] if 't_infectious' in self.to_learn.keys() \
+                else self.true_parameters['t_infectious']
+            sigma = predicted_parameters[self.to_learn['sigma']] if 'sigma' in self.to_learn.keys() \
+                else self.true_parameters['sigma']
+
+            current_densities = training_data[s].clone()
+            current_densities.requires_grad_(True)
+
+            loss = torch.tensor(0.0, requires_grad=True)
+
+            for ele in range(s + 1, s + batch_size + 1):
+
+                # Recovery rate
+                tau = 1 / t * torch.sigmoid(1000 * (ele / t - 1))
+
+                # Random noise
+                w = torch.normal(torch.tensor(0.0), torch.tensor(1.0))
+
+                # Solve the ODE
+                current_densities = current_densities + \
+                    torch.stack(
+                        [
+                            (- p * current_densities[0] + sigma * w) * current_densities[1],
+                            (p * current_densities[0] + sigma * w - tau) * current_densities[1],
+                            tau * current_densities[1]
+                        ]
+                    )
+
+                # Calculate loss
+                loss = loss + torch.nn.functional.mse_loss(current_densities, training_data[ele])/batch_size
+
+            loss.backward()
+            self.neural_net.optimizer.step()
+            self.neural_net.optimizer.zero_grad()
+            self.current_loss = loss.clone().detach().numpy().item()
+            self.current_predictions = predicted_parameters.clone().detach()
+            if 't_infectious' in self.to_learn.keys():
+                self.current_predictions[self.to_learn['t_infectious']] *= 10
             self.write_data()
             self._time += 1
 
-        self._ABM.reset()
-        #prediction = self._neural_net(training_data[0:0 + batch_size])
-
     def write_data(self):
         """Write the current state (loss and parameter predictions) into the state dataset.
 
@@ -225,12 +208,12 @@ class SIR_NN:
         data is always in the last row of the dataset.
         """
         if self._time >= self._write_start and (self._time % self._write_every == 0):
-
             self._dset_loss.resize(self._dset_loss.shape[0] + 1, axis=0)
-            self._dset_loss[-1, :] = self._current_loss
+            self._dset_loss[-1, :] = self.current_loss
 
-            self._dset_p_infect.resize(self._dset_p_infect.shape[0] + 1, axis=0)
-            self._dset_p_infect[-1] = self._current_predictions
+            for idx, dset in enumerate(self.dsets):
+                dset.resize(dset.shape[0]+1, axis=0)
+                dset[-1] = self.current_predictions[idx]
 
 # -----------------------------------------------------------------------------
 # -- Performing the simulation run --------------------------------------------
@@ -265,51 +248,49 @@ if __name__ == "__main__":
     h5file = h5.File(cfg["output_path"], mode="w")
     h5group = h5file.create_group(model_name)
 
-    # Initialise the ABM
-    print("\nInitializing the ABM ...")
-    ABM = SIR.SIR_ABM(**model_cfg['Data'])
+    # Get the training data
+    print("\nGenerating synthetic training data ...")
+    training_data = SIR.get_SIR_data(data_cfg=model_cfg['Data'], h5group=h5group)
 
     # Initialise the neural net
     print("\nInitializing the neural net ...")
-    net = base.NeuralNet(input_size=1, output_size=1, **model_cfg['NeuralNet'])
+    batch_size = model_cfg['Training']['batch_size']
+    net = base.NeuralNet(input_size=3, output_size=len(model_cfg['Training']['to_learn']),
+                         **model_cfg['NeuralNet'])
 
     # Initialise the model
     model = SIR_NN(
-        model_name, rng=rng, h5group=h5group, neural_net=net, ABM=ABM,
+        model_name, rng=rng, h5group=h5group, neural_net=net,
+        to_learn = model_cfg['Training']['to_learn'],
+        true_parameters = model_cfg['Training'].pop('true_parameters', {}),
         write_every=cfg['write_every'], write_start=cfg['write_start'],
-        num_steps=model_cfg['Data']['num_steps']
+        num_steps=len(training_data)
     )
     print(f"Initialized model '{model_name}'.")
 
-    # Generate the synthetic data
-    print("\nGenerating synthetic data ...")
-    model.generate_synthetic_data()
-
     num_epochs = cfg["num_epochs"]
     print(f"\nNow commencing training for {num_epochs} epochs ...")
-
     for i in range(num_epochs):
-
-        model.epoch(batch_size=model_cfg['Training']['batch_size'])
-
-        print(f"  Completed epoch {i + 1} / {num_epochs}.")
+        model.epoch(training_data=training_data, batch_size=batch_size)
+        print(f"  Completed epoch {i + 1} / {num_epochs}; current loss: {model.current_loss}")
 
     # Generate a complete dataset using the predicted parameters
     print("\nGenerating predicted dataset ...")
-    model.generate_prediction()
-
-    # Train the neural net
-    # num_epochs = cfg["num_epochs"]
-    # print(f"\nNow commencing training for {num_epochs} epochs ...")
-    # for i in range(num_epochs):
-    #
-    #     model.epoch(training_data=dest_sizes, batch_size=model_cfg['Training']['batch_size'],
-    #                 sigma=model_cfg['Training']['training_noise'])
-    #
-    #     print(f"  Completed epoch {i+1} / {num_epochs}.")
-    #
-    # print("\nSimulation run finished.")
-    # print("  Wrapping up ...")
+    parameters = torch.empty(3, dtype=torch.float)
+
+    for idx, item in enumerate(['p_infect', 't_infectious', 'sigma']):
+        if item in model.to_learn.keys():
+            parameters[idx] = model.current_predictions[model.to_learn[item]]
+        else:
+            parameters[idx] = model.true_parameters[item]
+
+    SIR.generate_smooth_data(init_state=training_data[0],
+                             counts=model._dset_pred_counts,
+                             num_steps=len(training_data),
+                             parameters=parameters, )
+
+    print("\nSimulation run finished.")
+    print("  Wrapping up ...")
     h5file.close()
 
     print("  All done.")
diff --git a/run_cfg.yml b/run_cfg.yml
index ffb790f..8dc620c 100644
--- a/run_cfg.yml
+++ b/run_cfg.yml
@@ -1,23 +1,37 @@
 ---
 parameter_space:
-  seed: 0
-  num_epochs: 2
+  seed: 21
+  num_epochs: 50
   write_start: 1
   write_every: 1
-  HarrisWilson:
-    Data:
-      load_from_dir: data/synthetic_data/N_1000_M_100/sigma_0
   SIR:
     Data:
-      N: 150
-      r_infectious: 1.0
-      p_infect: 0.15
-      t_infectious: 30
-      sigma_s: 0.15
-      sigma_i: 0.03
-      sigma_r: 0.15
-      dt: 0.01
-
+#      load_from_dir: /Users/thomasgaskin/utopya_output/SIR/low_diffusion/data/uni0/data.h5
+      synthetic_data:
+        type: from_ABM
+        N: 3000
+        r_infectious: 0.3
+        p_infect: 0.2
+        t_infectious: 14
+        num_steps: 100
+        sigma: 0.1
+        sigma_s: 0.02
+        sigma_i: 0.01
+        sigma_r: 0.02
+        is_periodic: true
+    NeuralNet:
+      num_layers: 20
+      nodes_per_layer: 20
+      bias: True
+      init_bias: [0, 1]
+      activation_funcs:
+        -1: abs
+      learning_rate: 0.0005
+    Training:
+      batch_size: 10
+      to_learn: [p_infect, t_infectious]
+      true_parameters:
+        sigma: 0.0